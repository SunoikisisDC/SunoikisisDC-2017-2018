{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech tagging and lemmatisation with üêç\n",
    "\n",
    "See information on the [Sunoikisis Wiki](https://github.com/SunoikisisDC/SunoikisisDC-2017-2018/wiki/Python-2:-Part-of-Speech-tagging-and-lemmatisation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "* present tools/libraries that can be used for PoS tagging and lemmatisation\n",
    "    * [CLTK](http://cltk.org/)\n",
    "    * [TreeTagger](http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/)\n",
    "    * [Collatinus](https://github.com/biblissima/collatinus) / [pyCollatinus](https://github.com/PonteIneptique/collatinus-python)\n",
    "* have a peek into what \"goes on\" behind the scenes, and that libraries make transparent to the user\n",
    "* show that there is a growing amount of python code/libraries for linguistic annotation on Anc Greek/Latin\n",
    "* ... but same time it takes a bit of bricolage to get things to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import cltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.83'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cltk.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.corpus.utils.importer import CorpusImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grk_corpus_importer = CorpusImporter('greek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greek_software_tlgu',\n",
       " 'greek_text_perseus',\n",
       " 'phi7',\n",
       " 'tlg',\n",
       " 'greek_proper_names_cltk',\n",
       " 'greek_models_cltk',\n",
       " 'greek_treebank_perseus',\n",
       " 'greek_lexica_perseus',\n",
       " 'greek_training_set_sentence_cltk',\n",
       " 'greek_word2vec_cltk',\n",
       " 'greek_text_lacus_curtius',\n",
       " 'greek_text_first1kgreek']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grk_corpus_importer.list_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grk_corpus_importer.import_corpus('greek_text_perseus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.corpus.latin import latinlibrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_corpus_importer = CorpusImporter('latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latin_text_perseus',\n",
       " 'latin_treebank_perseus',\n",
       " 'latin_text_latin_library',\n",
       " 'phi5',\n",
       " 'phi7',\n",
       " 'latin_proper_names_cltk',\n",
       " 'latin_models_cltk',\n",
       " 'latin_pos_lemmata_cltk',\n",
       " 'latin_treebank_index_thomisticus',\n",
       " 'latin_lexica_perseus',\n",
       " 'latin_training_set_sentence_cltk',\n",
       " 'latin_word2vec_cltk',\n",
       " 'latin_text_antique_digiliblt',\n",
       " 'latin_text_corpus_grammaticorum_latinorum',\n",
       " 'latin_text_poeti_ditalia']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_corpus_importer.list_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_corpus_importer.import_corpus('latin_training_set_sentence_cltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_corpus_importer.import_corpus('latin_text_latin_library')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.corpus.latin import latinlibrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.plaintext.PlaintextCorpusReader"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(latinlibrary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "amicitia_words = latinlibrary.words('cicero/amic.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11618"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amicitia_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12tables.txt',\n",
       " '1644.txt',\n",
       " 'abbofloracensis.txt',\n",
       " 'abelard/dialogus.txt',\n",
       " 'abelard/epistola.txt',\n",
       " 'abelard/historia.txt',\n",
       " 'addison/barometri.txt',\n",
       " 'addison/burnett.txt',\n",
       " 'addison/hannes.txt',\n",
       " 'addison/machinae.txt',\n",
       " 'addison/pax.txt',\n",
       " 'addison/praelium.txt',\n",
       " 'addison/preface.txt',\n",
       " 'addison/resurr.txt',\n",
       " 'addison/sphaer.txt',\n",
       " 'adso.txt',\n",
       " 'aelredus.txt',\n",
       " 'agnes.txt',\n",
       " 'alanus/alanus1.txt',\n",
       " 'alanus/alanus2.txt',\n",
       " 'albertanus/albertanus.arsloquendi.txt',\n",
       " 'albertanus/albertanus.liberconsol.txt',\n",
       " 'albertanus/albertanus.sermo.txt',\n",
       " 'albertanus/albertanus.sermo1.txt',\n",
       " 'albertanus/albertanus.sermo2.txt',\n",
       " 'albertanus/albertanus.sermo3.txt',\n",
       " 'albertanus/albertanus.sermo4.txt',\n",
       " 'albertanus/albertanus1.txt',\n",
       " 'albertanus/albertanus2.txt',\n",
       " 'albertanus/albertanus3.txt',\n",
       " 'albertanus/albertanus4.txt',\n",
       " 'albertofaix/hist1.txt',\n",
       " 'albertofaix/hist10.txt',\n",
       " 'albertofaix/hist11.txt',\n",
       " 'albertofaix/hist12.txt',\n",
       " 'albertofaix/hist2.txt',\n",
       " 'albertofaix/hist3.txt',\n",
       " 'albertofaix/hist4.txt',\n",
       " 'albertofaix/hist5.txt',\n",
       " 'albertofaix/hist6.txt',\n",
       " 'albertofaix/hist7.txt',\n",
       " 'albertofaix/hist8.txt',\n",
       " 'albertofaix/hist9.txt',\n",
       " 'alcuin/cella.txt',\n",
       " 'alcuin/conflictus.txt',\n",
       " 'alcuin/epitaphium.txt',\n",
       " 'alcuin/luscinia.txt',\n",
       " 'alcuin/propos.txt',\n",
       " 'alcuin/rec.txt',\n",
       " 'alcuin/rhetorica.txt',\n",
       " 'alcuin/sequentia.txt',\n",
       " 'alcuin/versus.txt',\n",
       " 'alfonsi.disciplina.txt',\n",
       " 'ambrose/epist.txt',\n",
       " 'ambrose/epistvaria.txt',\n",
       " 'ambrose/hymns.txt',\n",
       " 'ambrose/mysteriis.txt',\n",
       " 'ammianus/14.txt',\n",
       " 'ammianus/15.txt',\n",
       " 'ammianus/16.txt',\n",
       " 'ammianus/17.txt',\n",
       " 'ammianus/18.txt',\n",
       " 'ammianus/19.txt',\n",
       " 'ammianus/20.txt',\n",
       " 'ammianus/21.txt',\n",
       " 'ammianus/22.txt',\n",
       " 'ammianus/23.txt',\n",
       " 'ammianus/24.txt',\n",
       " 'ammianus/25.txt',\n",
       " 'ammianus/26.txt',\n",
       " 'ammianus/27.txt',\n",
       " 'ammianus/28.txt',\n",
       " 'ammianus/29.txt',\n",
       " 'ammianus/30.txt',\n",
       " 'ammianus/31.txt',\n",
       " 'ampelius.txt',\n",
       " 'andecavis.txt',\n",
       " 'andreasbergoma.txt',\n",
       " 'andronicus.txt',\n",
       " 'angilbert.txt',\n",
       " 'annalesregnifrancorum.txt',\n",
       " 'annalesvedastini.txt',\n",
       " 'anon.deramis.txt',\n",
       " 'anon.martyrio.txt',\n",
       " 'anon.nev.txt',\n",
       " 'anselmepistula.txt',\n",
       " 'anselmproslogion.txt',\n",
       " 'apicius/apicius1.txt',\n",
       " 'apicius/apicius2.txt',\n",
       " 'apicius/apicius3.txt',\n",
       " 'apicius/apicius4.txt',\n",
       " 'apicius/apicius5.txt',\n",
       " 'appverg.aetna.txt',\n",
       " 'appverg.catalepton.txt',\n",
       " 'appverg.ciris.txt',\n",
       " 'appvergcomp.txt',\n",
       " 'appvergculex.txt',\n",
       " 'apuleius/apuleius.apol.txt',\n",
       " 'apuleius/apuleius.cupid.txt',\n",
       " 'apuleius/apuleius.deosocratis.txt',\n",
       " 'apuleius/apuleius.dog1.txt',\n",
       " 'apuleius/apuleius.dog2.txt',\n",
       " 'apuleius/apuleius.florida.txt',\n",
       " 'apuleius/apuleius.mundo.txt',\n",
       " 'apuleius/apuleius1.txt',\n",
       " 'apuleius/apuleius10.txt',\n",
       " 'apuleius/apuleius11.txt',\n",
       " 'apuleius/apuleius2.txt',\n",
       " 'apuleius/apuleius3.txt',\n",
       " 'apuleius/apuleius4.txt',\n",
       " 'apuleius/apuleius5.txt',\n",
       " 'apuleius/apuleius6.txt',\n",
       " 'apuleius/apuleius7.txt',\n",
       " 'apuleius/apuleius8.txt',\n",
       " 'apuleius/apuleius9.txt',\n",
       " 'aquinas/corpuschristi.txt',\n",
       " 'aquinas/ente.txt',\n",
       " 'aquinas/epist.txt',\n",
       " 'aquinas/expositio.txt',\n",
       " 'aquinas/p1.txt',\n",
       " 'aquinas/princ.txt',\n",
       " 'aquinas/prologus.txt',\n",
       " 'aquinas/q1.1.txt',\n",
       " 'aquinas/q1.10.txt',\n",
       " 'aquinas/q1.11.txt',\n",
       " 'aquinas/q1.12.txt',\n",
       " 'aquinas/q1.13.txt',\n",
       " 'aquinas/q1.14.txt',\n",
       " 'aquinas/q1.15.txt',\n",
       " 'aquinas/q1.16.txt',\n",
       " 'aquinas/q1.17.txt',\n",
       " 'aquinas/q1.18.txt',\n",
       " 'aquinas/q1.19.txt',\n",
       " 'aquinas/q1.2.txt',\n",
       " 'aquinas/q1.20.txt',\n",
       " 'aquinas/q1.21.txt',\n",
       " 'aquinas/q1.22.txt',\n",
       " 'aquinas/q1.23.txt',\n",
       " 'aquinas/q1.24.txt',\n",
       " 'aquinas/q1.25.txt',\n",
       " 'aquinas/q1.26.txt',\n",
       " 'aquinas/q1.27.txt',\n",
       " 'aquinas/q1.28.txt',\n",
       " 'aquinas/q1.29.txt',\n",
       " 'aquinas/q1.3.txt',\n",
       " 'aquinas/q1.30.txt',\n",
       " 'aquinas/q1.31.txt',\n",
       " 'aquinas/q1.32.txt',\n",
       " 'aquinas/q1.33.txt',\n",
       " 'aquinas/q1.34.txt',\n",
       " 'aquinas/q1.35.txt',\n",
       " 'aquinas/q1.36.txt',\n",
       " 'aquinas/q1.37.txt',\n",
       " 'aquinas/q1.38.txt',\n",
       " 'aquinas/q1.39.txt',\n",
       " 'aquinas/q1.4.txt',\n",
       " 'aquinas/q1.40.txt',\n",
       " 'aquinas/q1.41.txt',\n",
       " 'aquinas/q1.42.txt',\n",
       " 'aquinas/q1.43.txt',\n",
       " 'aquinas/q1.44.txt',\n",
       " 'aquinas/q1.45.txt',\n",
       " 'aquinas/q1.46.txt',\n",
       " 'aquinas/q1.47.txt',\n",
       " 'aquinas/q1.48.txt',\n",
       " 'aquinas/q1.49.txt',\n",
       " 'aquinas/q1.5.txt',\n",
       " 'aquinas/q1.50.txt',\n",
       " 'aquinas/q1.51.txt',\n",
       " 'aquinas/q1.52.txt',\n",
       " 'aquinas/q1.53.txt',\n",
       " 'aquinas/q1.54.txt',\n",
       " 'aquinas/q1.55.txt',\n",
       " 'aquinas/q1.56.txt',\n",
       " 'aquinas/q1.57.txt',\n",
       " 'aquinas/q1.58.txt',\n",
       " 'aquinas/q1.59.txt',\n",
       " 'aquinas/q1.6.txt',\n",
       " 'aquinas/q1.60.txt',\n",
       " 'aquinas/q1.61.txt',\n",
       " 'aquinas/q1.62.txt',\n",
       " 'aquinas/q1.63.txt',\n",
       " 'aquinas/q1.64.txt',\n",
       " 'aquinas/q1.65.txt',\n",
       " 'aquinas/q1.66.txt',\n",
       " 'aquinas/q1.67.txt',\n",
       " 'aquinas/q1.68.txt',\n",
       " 'aquinas/q1.69.txt',\n",
       " 'aquinas/q1.7.txt',\n",
       " 'aquinas/q1.70.txt',\n",
       " 'aquinas/q1.71.txt',\n",
       " 'aquinas/q1.72.txt',\n",
       " 'aquinas/q1.73.txt',\n",
       " 'aquinas/q1.74.txt',\n",
       " 'aquinas/q1.8.txt',\n",
       " 'aquinas/q1.80.txt',\n",
       " 'aquinas/q1.81.txt',\n",
       " 'aquinas/q1.82.txt',\n",
       " 'aquinas/q1.83.txt',\n",
       " 'aquinas/q1.86.txt',\n",
       " 'aquinas/q1.87.txt',\n",
       " 'aquinas/q1.9.txt',\n",
       " 'arbroath.txt',\n",
       " 'archpoet.txt',\n",
       " 'arnobius/arnobius1.txt',\n",
       " 'arnobius/arnobius2.txt',\n",
       " 'arnobius/arnobius3.txt',\n",
       " 'arnobius/arnobius4.txt',\n",
       " 'arnobius/arnobius5.txt',\n",
       " 'arnobius/arnobius6.txt',\n",
       " 'arnobius/arnobius7.txt',\n",
       " 'arnulf.txt',\n",
       " 'asconius.txt',\n",
       " 'asserius.txt',\n",
       " 'augustine/catechizandis.txt',\n",
       " 'augustine/civ1.txt',\n",
       " 'augustine/civ10.txt',\n",
       " 'augustine/civ11.txt',\n",
       " 'augustine/civ12.txt',\n",
       " 'augustine/civ13.txt',\n",
       " 'augustine/civ14.txt',\n",
       " 'augustine/civ15.txt',\n",
       " 'augustine/civ16.txt',\n",
       " 'augustine/civ17.txt',\n",
       " 'augustine/civ18.txt',\n",
       " 'augustine/civ19.txt',\n",
       " 'augustine/civ2.txt',\n",
       " 'augustine/civ20.txt',\n",
       " 'augustine/civ21.txt',\n",
       " 'augustine/civ22.txt',\n",
       " 'augustine/civ3.txt',\n",
       " 'augustine/civ4.txt',\n",
       " 'augustine/civ5.txt',\n",
       " 'augustine/civ6.txt',\n",
       " 'augustine/civ7.txt',\n",
       " 'augustine/civ8.txt',\n",
       " 'augustine/civ9.txt',\n",
       " 'augustine/conf1.txt',\n",
       " 'augustine/conf10.txt',\n",
       " 'augustine/conf11.txt',\n",
       " 'augustine/conf12.txt',\n",
       " 'augustine/conf13.txt',\n",
       " 'augustine/conf2.txt',\n",
       " 'augustine/conf3.txt',\n",
       " 'augustine/conf4.txt',\n",
       " 'augustine/conf5.txt',\n",
       " 'augustine/conf6.txt',\n",
       " 'augustine/conf7.txt',\n",
       " 'augustine/conf8.txt',\n",
       " 'augustine/conf9.txt',\n",
       " 'augustine/dia.txt',\n",
       " 'augustine/epistula.txt',\n",
       " 'augustine/fide.txt',\n",
       " 'augustine/iulianus1.txt',\n",
       " 'augustine/iulianus2.txt',\n",
       " 'augustine/reg.txt',\n",
       " 'augustine/serm1.txt',\n",
       " 'augustine/serm10.txt',\n",
       " 'augustine/serm11.txt',\n",
       " 'augustine/serm12.txt',\n",
       " 'augustine/serm13.txt',\n",
       " 'augustine/serm14.txt',\n",
       " 'augustine/serm15.txt',\n",
       " 'augustine/serm16.txt',\n",
       " 'augustine/serm17.txt',\n",
       " 'augustine/serm18.txt',\n",
       " 'augustine/serm19.txt',\n",
       " 'augustine/serm2.txt',\n",
       " 'augustine/serm20.txt',\n",
       " 'augustine/serm4.txt',\n",
       " 'augustine/serm5.txt',\n",
       " 'augustine/serm6.txt',\n",
       " 'augustine/serm7.txt',\n",
       " 'augustine/serm71.txt',\n",
       " 'augustine/serm72.txt',\n",
       " 'augustine/serm73.txt',\n",
       " 'augustine/serm74.txt',\n",
       " 'augustine/serm75.txt',\n",
       " 'augustine/serm76.txt',\n",
       " 'augustine/serm77.txt',\n",
       " 'augustine/serm78.txt',\n",
       " 'augustine/serm79.txt',\n",
       " 'augustine/serm8.txt',\n",
       " 'augustine/serm80.txt',\n",
       " 'augustine/serm81.txt',\n",
       " 'augustine/serm82.txt',\n",
       " 'augustine/serm83.txt',\n",
       " 'augustine/serm87.txt',\n",
       " 'augustine/serm88.txt',\n",
       " 'augustine/serm9.txt',\n",
       " 'augustine/serm90.txt',\n",
       " 'augustine/serm92.txt',\n",
       " 'augustine/serm95.txt',\n",
       " 'augustine/serm99.txt',\n",
       " 'augustine/trin1.txt',\n",
       " 'augustine/trin10.txt',\n",
       " 'augustine/trin11.txt',\n",
       " 'augustine/trin12.txt',\n",
       " 'augustine/trin13.txt',\n",
       " 'augustine/trin14.txt',\n",
       " 'augustine/trin15.txt',\n",
       " 'augustine/trin2.txt',\n",
       " 'augustine/trin3.txt',\n",
       " 'augustine/trin4.txt',\n",
       " 'augustine/trin5.txt',\n",
       " 'augustine/trin6.txt',\n",
       " 'augustine/trin7.txt',\n",
       " 'augustine/trin8.txt',\n",
       " 'augustine/trin9.txt',\n",
       " 'aus.mos.txt',\n",
       " 'aus.sept.sent.txt',\n",
       " 'ave.phoen.txt',\n",
       " 'avianus.txt',\n",
       " 'avienus.ora.txt',\n",
       " 'avienus.periegesis.txt',\n",
       " 'axio.txt',\n",
       " 'bacon/bacon.distributio.txt',\n",
       " 'bacon/bacon.epistola.txt',\n",
       " 'bacon/bacon.hist1.txt',\n",
       " 'bacon/bacon.hist10.txt',\n",
       " 'bacon/bacon.hist11.txt',\n",
       " 'bacon/bacon.hist2.txt',\n",
       " 'bacon/bacon.hist3.txt',\n",
       " 'bacon/bacon.hist4.txt',\n",
       " 'bacon/bacon.hist5.txt',\n",
       " 'bacon/bacon.hist6.txt',\n",
       " 'bacon/bacon.hist7.txt',\n",
       " 'bacon/bacon.hist8.txt',\n",
       " 'bacon/bacon.hist9.txt',\n",
       " 'bacon/bacon.intro.txt',\n",
       " 'bacon/bacon.liber1.txt',\n",
       " 'bacon/bacon.liber2.txt',\n",
       " 'bacon/bacon.praefatio.txt',\n",
       " 'bacon/bacon.praefatio2.txt',\n",
       " 'bacon/bacon.sermones.txt',\n",
       " 'bacon/bacon.titlepage.txt',\n",
       " 'balbus.txt',\n",
       " 'balde1.txt',\n",
       " 'balde2.txt',\n",
       " 'baldo.txt',\n",
       " 'bebel.txt',\n",
       " 'bede/bede1.txt',\n",
       " 'bede/bede2.txt',\n",
       " 'bede/bede3.txt',\n",
       " 'bede/bede4.txt',\n",
       " 'bede/bede5.txt',\n",
       " 'bede/bedecontinuatio.txt',\n",
       " 'bede/bedepraef.txt',\n",
       " 'bede/bedeproverbs.txt',\n",
       " 'benedict.txt',\n",
       " 'berengar.txt',\n",
       " 'bernardcluny1.txt',\n",
       " 'bernardcluny2.txt',\n",
       " 'bible/acts.txt',\n",
       " 'bible/amos.txt',\n",
       " 'bible/baruch.txt',\n",
       " 'bible/chronicles1.txt',\n",
       " 'bible/chronicles2.txt',\n",
       " 'bible/colossians.txt',\n",
       " 'bible/corinthians1.txt',\n",
       " 'bible/corinthians2.txt',\n",
       " 'bible/daniel.txt',\n",
       " 'bible/deuteronomy.txt',\n",
       " 'bible/ecclesiastes.txt',\n",
       " 'bible/ephesians.txt',\n",
       " 'bible/esdras1.txt',\n",
       " 'bible/esdras2.txt',\n",
       " 'bible/esther.txt',\n",
       " 'bible/exodus.txt',\n",
       " 'bible/ezekiel.txt',\n",
       " 'bible/ezra.txt',\n",
       " 'bible/galatians.txt',\n",
       " 'bible/genesis.txt',\n",
       " 'bible/habakkuk.txt',\n",
       " 'bible/haggai.txt',\n",
       " 'bible/hebrews.txt',\n",
       " 'bible/hosea.txt',\n",
       " 'bible/isaiah.txt',\n",
       " 'bible/james.txt',\n",
       " 'bible/jeremiah.txt',\n",
       " 'bible/job.txt',\n",
       " 'bible/joel.txt',\n",
       " 'bible/john.txt',\n",
       " 'bible/john1.txt',\n",
       " 'bible/john2.txt',\n",
       " 'bible/john3.txt',\n",
       " 'bible/jonah.txt',\n",
       " 'bible/joshua.txt',\n",
       " 'bible/jude.txt',\n",
       " 'bible/judges.txt',\n",
       " 'bible/judith.txt',\n",
       " 'bible/kings1.txt',\n",
       " 'bible/kings2.txt',\n",
       " 'bible/lamentations.txt',\n",
       " 'bible/leviticus.txt',\n",
       " 'bible/luke.txt',\n",
       " 'bible/macabees1.txt',\n",
       " 'bible/macabees2.txt',\n",
       " 'bible/malachias.txt',\n",
       " 'bible/manasses.txt',\n",
       " 'bible/mark.txt',\n",
       " 'bible/matthew.txt',\n",
       " 'bible/micah.txt',\n",
       " 'bible/nahum.txt',\n",
       " 'bible/nehemiah.txt',\n",
       " 'bible/numbers.txt',\n",
       " 'bible/obadiah.txt',\n",
       " 'bible/peter1.txt',\n",
       " 'bible/peter2.txt',\n",
       " 'bible/philemon.txt',\n",
       " 'bible/philip.txt',\n",
       " 'bible/prologi.txt',\n",
       " 'bible/proverbs.txt',\n",
       " 'bible/psalms.txt',\n",
       " 'bible/revelation.txt',\n",
       " 'bible/romans.txt',\n",
       " 'bible/ruth.txt',\n",
       " 'bible/samuel1.txt',\n",
       " 'bible/samuel2.txt',\n",
       " 'bible/sirach.txt',\n",
       " 'bible/songofsongs.txt',\n",
       " 'bible/thessalonians1.txt',\n",
       " 'bible/thessalonians2.txt',\n",
       " 'bible/timothy1.txt',\n",
       " 'bible/timothy2.txt',\n",
       " 'bible/titum.txt',\n",
       " 'bible/tobia.txt',\n",
       " 'bible/wisdom.txt',\n",
       " 'bible/zacharias.txt',\n",
       " 'bible/zephaniah.txt',\n",
       " 'biggs.txt',\n",
       " 'bill.rights.txt',\n",
       " 'blesensis.txt',\n",
       " 'boethiusdacia/deaeternitate.txt',\n",
       " 'boethiusdacia/desummobono.txt',\n",
       " 'bonaventura.itinerarium.txt',\n",
       " 'boskovic.txt',\n",
       " 'brevechronicon.txt',\n",
       " 'buchanan.txt',\n",
       " 'bultelius/bultelius1.txt',\n",
       " 'bultelius/bultelius2.txt',\n",
       " 'caeciliusbalbus.txt',\n",
       " 'caesar/alex.txt',\n",
       " 'caesar/bc1.txt',\n",
       " 'caesar/bc2.txt',\n",
       " 'caesar/bc3.txt',\n",
       " 'caesar/bellafr.txt',\n",
       " 'caesar/gall1.txt',\n",
       " 'caesar/gall2.txt',\n",
       " 'caesar/gall3.txt',\n",
       " 'caesar/gall4.txt',\n",
       " 'caesar/gall5.txt',\n",
       " 'caesar/gall6.txt',\n",
       " 'caesar/gall7.txt',\n",
       " 'caesar/gall8.txt',\n",
       " 'caesar/hisp.txt',\n",
       " 'calpurniusflaccus.txt',\n",
       " 'calpurniussiculus.txt',\n",
       " 'campion/campion.elegies.txt',\n",
       " 'campion/campion.epigr1.txt',\n",
       " 'campion/campion.epigr2.txt',\n",
       " 'campion/campion.misc.txt',\n",
       " 'campion/campion.plot1.txt',\n",
       " 'campion/campion.plot2.txt',\n",
       " 'campion/campion.thamesin.txt',\n",
       " 'campion/campion.umbra.txt',\n",
       " 'capellanus/capellanus1.txt',\n",
       " 'capellanus/capellanus2.txt',\n",
       " 'capellanus/capellanus3.txt',\n",
       " 'carm.bur.txt',\n",
       " 'carmenarvale.txt',\n",
       " 'carmeninvictoriam.txt',\n",
       " 'carmensaliare.txt',\n",
       " 'cassiodorus/anima.txt',\n",
       " 'cassiodorus/epist.txt',\n",
       " 'cassiodorus/musica.txt',\n",
       " 'cassiodorus/orationes.txt',\n",
       " 'cassiodorus/varia.praef.txt',\n",
       " 'cassiodorus/varia1.txt',\n",
       " 'cassiodorus/varia10.txt',\n",
       " 'cassiodorus/varia11.txt',\n",
       " 'cassiodorus/varia12.txt',\n",
       " 'cassiodorus/varia2.txt',\n",
       " 'cassiodorus/varia3.txt',\n",
       " 'cassiodorus/varia4.txt',\n",
       " 'cassiodorus/varia5.txt',\n",
       " 'cassiodorus/varia6.txt',\n",
       " 'cassiodorus/varia7.txt',\n",
       " 'cassiodorus/varia8.txt',\n",
       " 'cassiodorus/varia9.txt',\n",
       " 'catalogueliberien.txt',\n",
       " 'cato.dis.txt',\n",
       " 'cato/cato.agri.txt',\n",
       " 'cato/cato.frag.txt',\n",
       " 'catullus.txt',\n",
       " 'celtis.odes.txt',\n",
       " 'celtis.oratio.txt',\n",
       " 'censorinus.txt',\n",
       " 'cicero/acad.txt',\n",
       " 'cicero/adbrutum1.txt',\n",
       " 'cicero/adbrutum2.txt',\n",
       " 'cicero/amic.txt',\n",
       " 'cicero/arch.txt',\n",
       " 'cicero/att1.txt',\n",
       " 'cicero/att10.txt',\n",
       " 'cicero/att11.txt',\n",
       " 'cicero/att12.txt',\n",
       " 'cicero/att13.txt',\n",
       " 'cicero/att14.txt',\n",
       " 'cicero/att15.txt',\n",
       " 'cicero/att16.txt',\n",
       " 'cicero/att2.txt',\n",
       " 'cicero/att3.txt',\n",
       " 'cicero/att4.txt',\n",
       " 'cicero/att5.txt',\n",
       " 'cicero/att6.txt',\n",
       " 'cicero/att7.txt',\n",
       " 'cicero/att8.txt',\n",
       " 'cicero/att9.txt',\n",
       " 'cicero/balbo.txt',\n",
       " 'cicero/brut.txt',\n",
       " 'cicero/caecilium.txt',\n",
       " 'cicero/caecina.txt',\n",
       " 'cicero/cael.txt',\n",
       " 'cicero/cat1.txt',\n",
       " 'cicero/cat2.txt',\n",
       " 'cicero/cat3.txt',\n",
       " 'cicero/cat4.txt',\n",
       " 'cicero/cluentio.txt',\n",
       " 'cicero/compet.txt',\n",
       " 'cicero/consulatu.txt',\n",
       " 'cicero/deio.txt',\n",
       " 'cicero/divinatione.txt',\n",
       " 'cicero/divinatione1.txt',\n",
       " 'cicero/divinatione2.txt',\n",
       " 'cicero/domo.txt',\n",
       " 'cicero/fam1.txt',\n",
       " 'cicero/fam10.txt',\n",
       " 'cicero/fam11.txt',\n",
       " 'cicero/fam12.txt',\n",
       " 'cicero/fam13.txt',\n",
       " 'cicero/fam14.txt',\n",
       " 'cicero/fam15.txt',\n",
       " 'cicero/fam16.txt',\n",
       " 'cicero/fam2.txt',\n",
       " 'cicero/fam3.txt',\n",
       " 'cicero/fam4.txt',\n",
       " 'cicero/fam5.txt',\n",
       " 'cicero/fam6.txt',\n",
       " 'cicero/fam7.txt',\n",
       " 'cicero/fam8.txt',\n",
       " 'cicero/fam9.txt',\n",
       " 'cicero/fato.txt',\n",
       " 'cicero/fin1.txt',\n",
       " 'cicero/fin2.txt',\n",
       " 'cicero/fin3.txt',\n",
       " 'cicero/fin4.txt',\n",
       " 'cicero/fin5.txt',\n",
       " 'cicero/flacco.txt',\n",
       " 'cicero/fonteio.txt',\n",
       " 'cicero/fratrem1.txt',\n",
       " 'cicero/fratrem2.txt',\n",
       " 'cicero/fratrem3.txt',\n",
       " 'cicero/haruspicum.txt',\n",
       " 'cicero/imp.txt',\n",
       " 'cicero/inventione1.txt',\n",
       " 'cicero/inventione2.txt',\n",
       " 'cicero/leg1.txt',\n",
       " 'cicero/leg2.txt',\n",
       " 'cicero/leg3.txt',\n",
       " 'cicero/legagr1.txt',\n",
       " 'cicero/legagr2.txt',\n",
       " 'cicero/legagr3.txt',\n",
       " 'cicero/lig.txt',\n",
       " 'cicero/marc.txt',\n",
       " 'cicero/milo.txt',\n",
       " 'cicero/murena.txt',\n",
       " 'cicero/nd.txt',\n",
       " 'cicero/nd1.txt',\n",
       " 'cicero/nd2.txt',\n",
       " 'cicero/nd3.txt',\n",
       " 'cicero/off1.txt',\n",
       " 'cicero/off2.txt',\n",
       " 'cicero/off3.txt',\n",
       " 'cicero/optgen.txt',\n",
       " 'cicero/orator.txt',\n",
       " 'cicero/oratore1.txt',\n",
       " 'cicero/oratore2.txt',\n",
       " 'cicero/oratore3.txt',\n",
       " 'cicero/paradoxa.txt',\n",
       " 'cicero/partitione.txt',\n",
       " 'cicero/phil1.txt',\n",
       " 'cicero/phil10.txt',\n",
       " 'cicero/phil11.txt',\n",
       " 'cicero/phil12.txt',\n",
       " 'cicero/phil13.txt',\n",
       " 'cicero/phil14.txt',\n",
       " 'cicero/phil2.txt',\n",
       " 'cicero/phil3.txt',\n",
       " 'cicero/phil4.txt',\n",
       " 'cicero/phil5.txt',\n",
       " 'cicero/phil6.txt',\n",
       " 'cicero/phil7.txt',\n",
       " 'cicero/phil8.txt',\n",
       " 'cicero/phil9.txt',\n",
       " 'cicero/piso.txt',\n",
       " 'cicero/plancio.txt',\n",
       " 'cicero/postreditum.txt',\n",
       " 'cicero/postreditum2.txt',\n",
       " 'cicero/prov.txt',\n",
       " 'cicero/quinc.txt',\n",
       " 'cicero/rabirio.txt',\n",
       " 'cicero/rabiriopost.txt',\n",
       " 'cicero/repub1.txt',\n",
       " 'cicero/repub2.txt',\n",
       " 'cicero/repub3.txt',\n",
       " 'cicero/repub4.txt',\n",
       " 'cicero/repub5.txt',\n",
       " 'cicero/repub6.txt',\n",
       " 'cicero/rosccom.txt',\n",
       " 'cicero/scauro.txt',\n",
       " 'cicero/senectute.txt',\n",
       " 'cicero/sestio.txt',\n",
       " 'cicero/sex.rosc.txt',\n",
       " 'cicero/sulla.txt',\n",
       " 'cicero/topica.txt',\n",
       " 'cicero/tusc1.txt',\n",
       " 'cicero/tusc2.txt',\n",
       " 'cicero/tusc3.txt',\n",
       " 'cicero/tusc4.txt',\n",
       " 'cicero/tusc5.txt',\n",
       " 'cicero/vatin.txt',\n",
       " 'cicero/ver1.txt',\n",
       " 'cicero/verres.2.1.txt',\n",
       " 'cicero/verres.2.2.txt',\n",
       " 'cicero/verres.2.3.txt',\n",
       " 'cicero/verres.2.4.txt',\n",
       " 'cicero/verres.2.5.txt',\n",
       " 'cinna.txt',\n",
       " 'claud.inscr.txt',\n",
       " 'claudian/claudian.cons6.txt',\n",
       " 'claudian/claudian.olyb.txt',\n",
       " 'claudian/claudian.proserp1.txt',\n",
       " 'claudian/claudian.proserp2.txt',\n",
       " 'claudian/claudian.proserp3.txt',\n",
       " 'claudian/claudian.ruf1.txt',\n",
       " 'clitophon.txt',\n",
       " 'colman.txt',\n",
       " 'columba1.txt',\n",
       " 'columba2.txt',\n",
       " 'columbus.txt',\n",
       " 'columella/columella.arbor.txt',\n",
       " 'columella/columella.rr1.txt',\n",
       " 'columella/columella.rr10.txt',\n",
       " 'columella/columella.rr11.txt',\n",
       " 'columella/columella.rr12.txt',\n",
       " 'columella/columella.rr2.txt',\n",
       " 'columella/columella.rr3.txt',\n",
       " 'columella/columella.rr4.txt',\n",
       " 'columella/columella.rr5.txt',\n",
       " 'columella/columella.rr6.txt',\n",
       " 'columella/columella.rr7.txt',\n",
       " 'columella/columella.rr8.txt',\n",
       " 'columella/columella.rr9.txt',\n",
       " 'comes.txt',\n",
       " 'commodianus/commodianus1.txt',\n",
       " 'commodianus/commodianus2.txt',\n",
       " 'commodianus/commodianus3.txt',\n",
       " 'corvinus1.txt',\n",
       " 'corvinus2.txt',\n",
       " 'cotta.txt',\n",
       " 'creeds.txt',\n",
       " 'curtius/curtius10.txt',\n",
       " 'curtius/curtius3.txt',\n",
       " 'curtius/curtius4.txt',\n",
       " 'curtius/curtius5.txt',\n",
       " 'curtius/curtius6.txt',\n",
       " 'curtius/curtius7.txt',\n",
       " 'curtius/curtius8.txt',\n",
       " 'curtius/curtius9.txt',\n",
       " 'dante/ec1.txt',\n",
       " 'dante/ep.txt',\n",
       " 'dante/mon1.txt',\n",
       " 'dante/mon2.txt',\n",
       " 'dante/mon3.txt',\n",
       " 'dante/vulgar.txt',\n",
       " 'dante/vulgar2.txt',\n",
       " 'dares.txt',\n",
       " 'dares1.txt',\n",
       " 'debury.txt',\n",
       " 'declaratio.txt',\n",
       " 'decretum.txt',\n",
       " 'descartes/des.ep.txt',\n",
       " 'descartes/des.med1.txt',\n",
       " 'descartes/des.med2.txt',\n",
       " 'descartes/des.med3.txt',\n",
       " 'descartes/des.med4.txt',\n",
       " 'descartes/des.med5.txt',\n",
       " 'descartes/des.med6.txt',\n",
       " 'descartes/des.pr.txt',\n",
       " 'descartes/des.syn.txt',\n",
       " 'dicchristi.txt',\n",
       " 'dicquid.txt',\n",
       " 'diesirae.txt',\n",
       " 'diravi.txt',\n",
       " 'don.txt',\n",
       " 'donation.txt',\n",
       " 'dulcesolum.txt',\n",
       " 'dumdiane.txt',\n",
       " 'dumdomus.txt',\n",
       " 'dumestas.txt',\n",
       " 'ebulo.txt',\n",
       " 'egeria1.txt',\n",
       " 'egeria2.txt',\n",
       " 'ein.txt',\n",
       " 'ency.fides.txt',\n",
       " 'enn.txt',\n",
       " 'ennodius.txt',\n",
       " 'ep.priapismo.txt',\n",
       " 'epistaustras.txt',\n",
       " 'epitaphs.txt',\n",
       " 'epitomecononiana.txt',\n",
       " 'epitomefeliciana.txt',\n",
       " 'erasmus/antibarb.txt',\n",
       " 'erasmus/coll.txt',\n",
       " 'erasmus/ep.txt',\n",
       " 'erasmus/inst.txt',\n",
       " 'erasmus/laude.txt',\n",
       " 'erasmus/moriae.txt',\n",
       " 'erasmus/querela.txt',\n",
       " 'erchempert.txt',\n",
       " 'estas.txt',\n",
       " 'eucherius.txt',\n",
       " 'eugenius.txt',\n",
       " 'eugippius.txt',\n",
       " 'eutropius/eutropius1.txt',\n",
       " 'eutropius/eutropius10.txt',\n",
       " 'eutropius/eutropius2.txt',\n",
       " 'eutropius/eutropius3.txt',\n",
       " 'eutropius/eutropius4.txt',\n",
       " 'eutropius/eutropius5.txt',\n",
       " 'eutropius/eutropius6.txt',\n",
       " 'eutropius/eutropius7.txt',\n",
       " 'eutropius/eutropius8.txt',\n",
       " 'eutropius/eutropius9.txt',\n",
       " 'exivi.txt',\n",
       " 'fabe.txt',\n",
       " 'falcandus.txt',\n",
       " 'falcone.txt',\n",
       " 'ferraria.txt',\n",
       " 'ficino.txt',\n",
       " 'fletcher.txt',\n",
       " 'florus1.txt',\n",
       " 'florus2.txt',\n",
       " 'foedusaeternum.txt',\n",
       " 'forsett1.txt',\n",
       " 'forsett2.txt',\n",
       " 'fortunat.txt',\n",
       " 'fragmentumlaurentianum.txt',\n",
       " 'fredegarius.txt',\n",
       " 'frodebertus.txt',\n",
       " 'frontinus/aqua1.txt',\n",
       " 'frontinus/aqua2.txt',\n",
       " 'frontinus/contro.txt',\n",
       " 'frontinus/lim.txt',\n",
       " 'frontinus/mensoria.txt',\n",
       " 'frontinus/qualitate.txt',\n",
       " 'frontinus/strat1.txt',\n",
       " 'frontinus/strat2.txt',\n",
       " 'frontinus/strat3.txt',\n",
       " 'frontinus/strat4.txt',\n",
       " 'fronto.txt',\n",
       " 'fulbert.txt',\n",
       " 'fulgentius/fulgentius1.txt',\n",
       " 'fulgentius/fulgentius2.txt',\n",
       " 'fulgentius/fulgentius3.txt',\n",
       " 'fulgentius/fulgentius4.txt',\n",
       " 'fulgentius/fulgentius5.txt',\n",
       " 'gaius1.txt',\n",
       " 'gaius2.txt',\n",
       " 'gaius3.txt',\n",
       " 'gaius4.txt',\n",
       " 'galileo/galileo.sid.txt',\n",
       " 'garcilaso.txt',\n",
       " 'garland.txt',\n",
       " 'gaud.txt',\n",
       " 'gauss.txt',\n",
       " 'gellius/gellius1.txt',\n",
       " 'gellius/gellius10.txt',\n",
       " 'gellius/gellius11.txt',\n",
       " 'gellius/gellius13.txt',\n",
       " 'gellius/gellius2.txt',\n",
       " 'gellius/gellius20.txt',\n",
       " 'gellius/gellius3.txt',\n",
       " 'gellius/gellius4.txt',\n",
       " 'gellius/gellius5.txt',\n",
       " 'gellius/gellius6.txt',\n",
       " 'gellius/gellius7.txt',\n",
       " 'gellius/gellius8.txt',\n",
       " 'gellius/gellius9.txt',\n",
       " 'gellius/gelliuscapitula.txt',\n",
       " 'gellius/gelliuspraef.txt',\n",
       " 'germanicus.txt',\n",
       " 'gestafrancorum/gestafrancorum1.txt',\n",
       " 'gestafrancorum/gestafrancorum10.txt',\n",
       " 'gestafrancorum/gestafrancorum2.txt',\n",
       " 'gestafrancorum/gestafrancorum3.txt',\n",
       " 'gestafrancorum/gestafrancorum4.txt',\n",
       " 'gestafrancorum/gestafrancorum5.txt',\n",
       " 'gestafrancorum/gestafrancorum6.txt',\n",
       " 'gestafrancorum/gestafrancorum7.txt',\n",
       " 'gestafrancorum/gestafrancorum8.txt',\n",
       " 'gestafrancorum/gestafrancorum9.txt',\n",
       " 'gestarom.txt',\n",
       " 'gioacchino.txt',\n",
       " 'godfrey.epigrammata.txt',\n",
       " 'godfrey.epigrammatahist.txt',\n",
       " 'grattius.txt',\n",
       " 'gravissimas.txt',\n",
       " 'greg.txt',\n",
       " 'gregdecretals1.txt',\n",
       " 'gregdecretals2.txt',\n",
       " 'gregdecretals3.txt',\n",
       " 'gregdecretals4.txt',\n",
       " 'gregdecretals5.txt',\n",
       " 'gregory.txt',\n",
       " 'gregory7.txt',\n",
       " 'gregorytours.txt',\n",
       " 'gregorytours/gregorytours1.txt',\n",
       " 'gregorytours/gregorytours10.txt',\n",
       " 'gregorytours/gregorytours2.txt',\n",
       " 'gregorytours/gregorytours3.txt',\n",
       " 'gregorytours/gregorytours4.txt',\n",
       " 'gregorytours/gregorytours5.txt',\n",
       " 'gregorytours/gregorytours6.txt',\n",
       " 'gregorytours/gregorytours7.txt',\n",
       " 'gregorytours/gregorytours8.txt',\n",
       " 'gregorytours/gregorytours9.txt',\n",
       " 'gwinne.txt',\n",
       " 'gwinne1.txt',\n",
       " 'gwinne2.txt',\n",
       " 'gwinne3.txt',\n",
       " 'gwinne4.txt',\n",
       " 'gwinne5.1.txt',\n",
       " 'gwinne5.2.txt',\n",
       " 'gwinne5.3.txt',\n",
       " 'gwinne5.4.txt',\n",
       " 'halley.txt',\n",
       " 'hebet.txt',\n",
       " 'henry.txt',\n",
       " 'henry1.txt',\n",
       " 'henry2.txt',\n",
       " 'henry3.txt',\n",
       " 'henrysettimello.txt',\n",
       " 'hipp.txt',\n",
       " 'histapoll.txt',\n",
       " 'histbrit.txt',\n",
       " 'holberg.txt',\n",
       " 'hor.txt',\n",
       " 'horace/arspoet.txt',\n",
       " 'horace/carm1.txt',\n",
       " 'horace/carm2.txt',\n",
       " 'horace/carm3.txt',\n",
       " 'horace/carm4.txt',\n",
       " 'horace/carmsaec.txt',\n",
       " 'horace/ep.txt',\n",
       " 'horace/epist1.txt',\n",
       " 'horace/epist2.txt',\n",
       " 'horace/serm1.txt',\n",
       " 'horace/serm2.txt',\n",
       " 'hrabanus.txt',\n",
       " 'hugo.txt',\n",
       " 'hugo/hugo.solo.txt',\n",
       " 'hugo/hugo1.txt',\n",
       " 'hugo/hugo2.txt',\n",
       " 'hugo/hugo3.txt',\n",
       " 'hugo/hugo4.txt',\n",
       " 'hugo/hugo5.txt',\n",
       " 'hugo/hugo6.txt',\n",
       " 'hydatius.txt',\n",
       " 'hydatiuschronicon.txt',\n",
       " 'hydatiusfasti.txt',\n",
       " 'hyginus/hyginus1.txt',\n",
       " 'hyginus/hyginus2.txt',\n",
       " 'hyginus/hyginus3.txt',\n",
       " 'hyginus/hyginus4.txt',\n",
       " 'hyginus/hyginus5.txt',\n",
       " 'hyginus/hyginus6.txt',\n",
       " 'hymni.txt',\n",
       " 'iabervocius.txt',\n",
       " 'iamdulcis.txt',\n",
       " 'ilias.txt',\n",
       " 'index.txt',\n",
       " 'indices.txt',\n",
       " 'innocent.txt',\n",
       " 'innocent1.txt',\n",
       " 'innocent2.txt',\n",
       " 'inquisitio.txt',\n",
       " 'inscriptions.txt',\n",
       " 'iordanes1.txt',\n",
       " 'iordanes2.txt',\n",
       " 'ipsavivere.txt',\n",
       " 'isidore.txt',\n",
       " 'isidore/1.txt',\n",
       " 'isidore/10.txt',\n",
       " 'isidore/11.txt',\n",
       " 'isidore/12.txt',\n",
       " 'isidore/13.txt',\n",
       " 'isidore/14.txt',\n",
       " 'isidore/15.txt',\n",
       " 'isidore/16.txt',\n",
       " 'isidore/17.txt',\n",
       " 'isidore/18.txt',\n",
       " 'isidore/19.txt',\n",
       " 'isidore/2.txt',\n",
       " 'isidore/20.txt',\n",
       " 'isidore/3.txt',\n",
       " 'isidore/4.txt',\n",
       " 'isidore/5.txt',\n",
       " 'isidore/6.txt',\n",
       " 'isidore/7.txt',\n",
       " 'isidore/8.txt',\n",
       " 'isidore/9.txt',\n",
       " 'isidore/historia.txt',\n",
       " 'isidore/sententiae1.txt',\n",
       " 'isidore/sententiae2.txt',\n",
       " 'isidore/sententiae3.txt',\n",
       " 'ius.txt',\n",
       " 'janus1.txt',\n",
       " 'janus2.txt',\n",
       " 'jerome/contraioannem.txt',\n",
       " 'jerome/epistulae.txt',\n",
       " 'jerome/vitamalchus.txt',\n",
       " 'jerome/vitapauli.txt',\n",
       " 'jfkhonor.txt',\n",
       " 'johannes.txt',\n",
       " 'junillus.txt',\n",
       " 'justin/1.txt',\n",
       " 'justin/10.txt',\n",
       " 'justin/11.txt',\n",
       " 'justin/12.txt',\n",
       " 'justin/13.txt',\n",
       " 'justin/14.txt',\n",
       " 'justin/15.txt',\n",
       " 'justin/16.txt',\n",
       " 'justin/17.txt',\n",
       " 'justin/18.txt',\n",
       " 'justin/19.txt',\n",
       " 'justin/2.txt',\n",
       " 'justin/20.txt',\n",
       " 'justin/21.txt',\n",
       " 'justin/22.txt',\n",
       " 'justin/23.txt',\n",
       " 'justin/24.txt',\n",
       " 'justin/25.txt',\n",
       " 'justin/26.txt',\n",
       " 'justin/27.txt',\n",
       " 'justin/28.txt',\n",
       " 'justin/29.txt',\n",
       " 'justin/3.txt',\n",
       " 'justin/30.txt',\n",
       " 'justin/31.txt',\n",
       " 'justin/32.txt',\n",
       " 'justin/33.txt',\n",
       " 'justin/34.txt',\n",
       " 'justin/35.txt',\n",
       " 'justin/36.txt',\n",
       " 'justin/37.txt',\n",
       " 'justin/38.txt',\n",
       " 'justin/39.txt',\n",
       " 'justin/4.txt',\n",
       " 'justin/40.txt',\n",
       " 'justin/41.txt',\n",
       " 'justin/42.txt',\n",
       " 'justin/43.txt',\n",
       " 'justin/44.txt',\n",
       " 'justin/5.txt',\n",
       " 'justin/6.txt',\n",
       " 'justin/7.txt',\n",
       " 'justin/8.txt',\n",
       " 'justin/9.txt',\n",
       " 'justin/praefatio.txt',\n",
       " 'justin/prologi.txt',\n",
       " 'justinian/codex1.txt',\n",
       " 'justinian/codex10.txt',\n",
       " 'justinian/codex11.txt',\n",
       " 'justinian/codex12.txt',\n",
       " 'justinian/codex2.txt',\n",
       " 'justinian/codex3.txt',\n",
       " 'justinian/codex4.txt',\n",
       " 'justinian/codex5.txt',\n",
       " 'justinian/codex6.txt',\n",
       " 'justinian/codex7.txt',\n",
       " 'justinian/codex8.txt',\n",
       " 'justinian/codex9.txt',\n",
       " 'justinian/digest1.txt',\n",
       " 'justinian/digest10.txt',\n",
       " 'justinian/digest11.txt',\n",
       " 'justinian/digest12.txt',\n",
       " 'justinian/digest13.txt',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latinlibrary.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get `n` number of tokens from this text by using the *slice notation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cicero',\n",
       " ':',\n",
       " 'de',\n",
       " 'Amicitia',\n",
       " 'M.',\n",
       " 'TVLLI',\n",
       " 'CICERONIS',\n",
       " 'LAELIVS',\n",
       " 'DE',\n",
       " 'AMICITIA']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first ten tokens\n",
    "amicitia_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or the last token\n",
    "amicitia_words[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also count occurrences by using the `count()` method and passing as parameter the token we want to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amicitia_words.count('et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amicitia_words.count('amicitia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look to the `type` of the variable `amicitia_words` where we loaded the content of Cicero's *De Amicitia*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.util.StreamBackedCorpusView"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(amicitia_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "amicitia_words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caveat**: `cltk.corpus.latin.latinlibrary` is a shortcut for several things, and there is nothing comparable (yet) for Greek (see [source code](https://github.com/cltk/cltk/blob/master/cltk/corpus/latin/__init__.py))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latin\n",
    "\n",
    "#### CLTK taggers\n",
    "\n",
    "CLTK documentation with runnable examples [here](http://docs.cltk.org/en/latest/latin.html#pos-tagging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gallia', None),\n",
       " ('est', 'V3SPIA---'),\n",
       " ('omnis', 'A-S---MN-'),\n",
       " ('divisa', 'T-PRPPNN-'),\n",
       " ('in', 'R--------'),\n",
       " ('partes', 'N-P---FA-'),\n",
       " ('tres', 'M--------')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cltk.tag.pos import POSTag\n",
    "tagger = POSTag('latin')\n",
    "tagger.tag_ngram_123_backoff('Gallia est omnis divisa in partes tres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is it failing?**\n",
    "\n",
    "CLTK relies on some components (e.g. trained models) that are read from disk instead of being generated on the fly.\n",
    "\n",
    "This is very common, especially in those cases where the time needed to generate certain objects is not negligible.\n",
    "\n",
    "`pickle` is the python library that does this, and *serialization* is the process of writing an object to disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_corpus_importer.list_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_corpus_importer.import_corpus('latin_models_cltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = POSTag('latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger.tag_tnt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('91', 'Unk'), ('91', None), ('91', 'A-P---FN-')),\n",
       " (('92', 'Unk'), ('92', None), ('92', 'N-P---FN-')),\n",
       " (('93', 'Unk'), ('93', None), ('93', 'A-P---FN-')),\n",
       " (('94', 'Unk'), ('94', None), ('94', 'N-P---FN-')),\n",
       " (('95', 'Unk'), ('95', None), ('95', 'A-P---FN-')),\n",
       " (('96', 'Unk'), ('96', None), ('96', 'N-P---FN-')),\n",
       " (('97', 'Unk'), ('97', None), ('97', 'A-P---FN-')),\n",
       " (('98', 'Unk'), ('98', None), ('98', 'N-P---FN-')),\n",
       " (('99', 'Unk'), ('99', None), ('99', 'A-P---FN-')),\n",
       " (('100', 'Unk'), ('100', None), ('100', 'N-P---FN-')),\n",
       " (('101', 'Unk'), ('101', None), ('101', 'A-P---FN-')),\n",
       " (('102', 'Unk'), ('102', None), ('102', 'N-P---FN-')),\n",
       " (('103', 'Unk'), ('103', None), ('103', 'A-P---FN-')),\n",
       " (('104', 'Unk'), ('104', None), ('104', 'N-P---FN-')),\n",
       " (('[', 'U--------'), ('[', 'U--------'), ('[', 'U--------')),\n",
       " (('1', 'Unk'), ('1', None), ('1', 'N-S---MV-')),\n",
       " ((']', 'U--------'), (']', 'U--------'), (']', 'U--------')),\n",
       " (('Q', 'Unk'), ('Q', None), ('Q', 'N-S---MV-')),\n",
       " (('.', 'U--------'), ('.', 'U--------'), ('.', 'U--------')),\n",
       " (('Mucius', 'Unk'), ('Mucius', None), ('Mucius', 'D--------')),\n",
       " (('augur', 'Unk'), ('augur', None), ('augur', 'D--------')),\n",
       " (('multa', 'A-P---NA-'), ('multa', 'A-P---NA-'), ('multa', 'A-P---NA-')),\n",
       " (('narrare', 'V--PNA---'),\n",
       "  ('narrare', 'V--PNA---'),\n",
       "  ('narrare', 'V--PNA---')),\n",
       " (('de', 'R--------'), ('de', 'R--------'), ('de', 'R--------')),\n",
       " (('C', 'Unk'), ('C', None), ('C', '---------')),\n",
       " (('.', 'U--------'), ('.', 'U--------'), ('.', 'U--------')),\n",
       " (('Laelio', 'Unk'), ('Laelio', None), ('Laelio', 'A-S---NB-')),\n",
       " (('socero', 'Unk'), ('socero', None), ('socero', 'N-S---NB-')),\n",
       " (('suo', 'A-S---NB-'), ('suo', 'A-S---NB-'), ('suo', 'A-S---NB-')),\n",
       " (('memoriter', 'Unk'), ('memoriter', None), ('memoriter', 'D--------')),\n",
       " (('et', 'C--------'), ('et', 'C--------'), ('et', 'C--------')),\n",
       " (('iucunde', 'Unk'), ('iucunde', None), ('iucunde', 'D--------')),\n",
       " (('solebat', 'V3SIIA---'),\n",
       "  ('solebat', 'V3SIIA---'),\n",
       "  ('solebat', 'V3SIIA---')),\n",
       " (('nec', 'C--------'), ('nec', 'C--------'), ('nec', 'C--------')),\n",
       " (('dubitare', 'Unk'), ('dubitare', None), ('dubitare', 'V--PNA---')),\n",
       " (('illum', 'P-S---MA-'), ('illum', 'P-S---MA-'), ('illum', 'P-S---MA-')),\n",
       " (('in', 'R--------'), ('in', 'R--------'), ('in', 'R--------')),\n",
       " (('omni', 'A-S---MB-'), ('omni', 'A-S---FB-'), ('omni', 'A-S---FB-')),\n",
       " (('sermone', 'N-S---MB-'),\n",
       "  ('sermone', 'N-S---MB-'),\n",
       "  ('sermone', 'N-S---FB-')),\n",
       " (('appellare', 'V--PNA---'),\n",
       "  ('appellare', 'V--PNA---'),\n",
       "  ('appellare', 'V--PNA---')),\n",
       " (('sapientem', 'Unk'), ('sapientem', None), ('sapientem', 'N-S---FA-')),\n",
       " ((';', 'Unk'), (';', None), (';', 'U--------')),\n",
       " (('ego', 'P-S---MN-'), ('ego', 'P-S---MN-'), ('ego', 'P-S---MN-')),\n",
       " (('autem', 'C--------'), ('autem', 'C--------'), ('autem', 'C--------')),\n",
       " (('a', 'R--------'), ('a', 'R--------'), ('a', 'R--------')),\n",
       " (('patre', 'N-S---MB-'), ('patre', 'N-S---MB-'), ('patre', 'N-S---MB-')),\n",
       " (('ita', 'D--------'), ('ita', 'D--------'), ('ita', 'D--------')),\n",
       " (('eram', 'V1SIIA---'), ('eram', 'V1SIIA---'), ('eram', 'N-S---FA-')),\n",
       " (('deductus', 'T-SRPPMN-'),\n",
       "  ('deductus', 'T-SRPPMN-'),\n",
       "  ('deductus', 'T-SRPPMN-')),\n",
       " (('ad', 'R--------'), ('ad', 'R--------'), ('ad', 'R--------')),\n",
       " (('Scaevolam', 'Unk'), ('Scaevolam', None), ('Scaevolam', 'N-S---FA-')),\n",
       " (('sumpta', 'Unk'), ('sumpta', None), ('sumpta', 'T-SRPPFN-'))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(\n",
    "    tagger.tag_tnt(\" \".join([str(w) for w in amicitia_words[100:150]])),\n",
    "    tagger.tag_ngram_123_backoff(\" \".join([str(w) for w in amicitia_words[100:150]])),\n",
    "    tagger.tag_crf(\" \".join([str(w) for w in amicitia_words[100:150]]))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to take sentences instead of ranges of tokens?\n",
    "\n",
    "The class `PlaintextCorpusReader` has a nice method ‚Äì `sents()` ‚Äì that does this.\n",
    "\n",
    "Let's see how it works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_amicitia_sentences = latinlibrary.sents('cicero/amic.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(de_amicitia_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cicero', ':', 'de', 'Amicitia'],\n",
       " ['M.', 'TVLLI', 'CICERONIS', 'LAELIVS', 'DE', 'AMICITIA'],\n",
       " ['1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  '6',\n",
       "  '7',\n",
       "  '8',\n",
       "  '9',\n",
       "  '10',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '14',\n",
       "  '15',\n",
       "  '16',\n",
       "  '17',\n",
       "  '18',\n",
       "  '19',\n",
       "  '20',\n",
       "  '21',\n",
       "  '22',\n",
       "  '23',\n",
       "  '24',\n",
       "  '25',\n",
       "  '26',\n",
       "  '27',\n",
       "  '28',\n",
       "  '29',\n",
       "  '30',\n",
       "  '31',\n",
       "  '32',\n",
       "  '33',\n",
       "  '34',\n",
       "  '35',\n",
       "  '36',\n",
       "  '37',\n",
       "  '38',\n",
       "  '39',\n",
       "  '40',\n",
       "  '41',\n",
       "  '42',\n",
       "  '43',\n",
       "  '44',\n",
       "  '45',\n",
       "  '46',\n",
       "  '47',\n",
       "  '48',\n",
       "  '49',\n",
       "  '50',\n",
       "  '51',\n",
       "  '52',\n",
       "  '53',\n",
       "  '54',\n",
       "  '55',\n",
       "  '56',\n",
       "  '57',\n",
       "  '58',\n",
       "  '59',\n",
       "  '60',\n",
       "  '61',\n",
       "  '62',\n",
       "  '63',\n",
       "  '64',\n",
       "  '65',\n",
       "  '66',\n",
       "  '67',\n",
       "  '68',\n",
       "  '69',\n",
       "  '70',\n",
       "  '71',\n",
       "  '72',\n",
       "  '73',\n",
       "  '74',\n",
       "  '75',\n",
       "  '76',\n",
       "  '77',\n",
       "  '78',\n",
       "  '79',\n",
       "  '80',\n",
       "  '81',\n",
       "  '82',\n",
       "  '83',\n",
       "  '84',\n",
       "  '85',\n",
       "  '86',\n",
       "  '87',\n",
       "  '88',\n",
       "  '89',\n",
       "  '90',\n",
       "  '91',\n",
       "  '92',\n",
       "  '93',\n",
       "  '94',\n",
       "  '95',\n",
       "  '96',\n",
       "  '97',\n",
       "  '98',\n",
       "  '99',\n",
       "  '100',\n",
       "  '101',\n",
       "  '102',\n",
       "  '103',\n",
       "  '104'],\n",
       " ['[',\n",
       "  '1',\n",
       "  ']',\n",
       "  'Q.',\n",
       "  'Mucius',\n",
       "  'augur',\n",
       "  'multa',\n",
       "  'narrare',\n",
       "  'de',\n",
       "  'C.',\n",
       "  'Laelio',\n",
       "  'socero',\n",
       "  'suo',\n",
       "  'memoriter',\n",
       "  'et',\n",
       "  'iucunde',\n",
       "  'solebat',\n",
       "  'nec',\n",
       "  'dubitare',\n",
       "  'illum',\n",
       "  'in',\n",
       "  'omni',\n",
       "  'sermone',\n",
       "  'appellare',\n",
       "  'sapientem',\n",
       "  ';',\n",
       "  'ego',\n",
       "  'autem',\n",
       "  'a',\n",
       "  'patre',\n",
       "  'ita',\n",
       "  'eram',\n",
       "  'deductus',\n",
       "  'ad',\n",
       "  'Scaevolam',\n",
       "  'sumpta',\n",
       "  'virili',\n",
       "  'toga',\n",
       "  ',',\n",
       "  'ut',\n",
       "  ',',\n",
       "  'quoad',\n",
       "  'possem',\n",
       "  'et',\n",
       "  'liceret',\n",
       "  ',',\n",
       "  'a',\n",
       "  'senis',\n",
       "  'latere',\n",
       "  'numquam',\n",
       "  'discederem',\n",
       "  ';',\n",
       "  'itaque',\n",
       "  'multa',\n",
       "  'ab',\n",
       "  'eo',\n",
       "  'prudenter',\n",
       "  'disputata',\n",
       "  ',',\n",
       "  'multa',\n",
       "  'etiam',\n",
       "  'breviter',\n",
       "  'et',\n",
       "  'commode',\n",
       "  'dicta',\n",
       "  'memoriae',\n",
       "  'mandabam',\n",
       "  'fieri',\n",
       "  '-que',\n",
       "  'studebam',\n",
       "  'eius',\n",
       "  'prudentia',\n",
       "  'doctior',\n",
       "  '.'],\n",
       " ['Quo',\n",
       "  'mortuo',\n",
       "  'me',\n",
       "  'ad',\n",
       "  'pontificem',\n",
       "  'Scaevolam',\n",
       "  'contuli',\n",
       "  ',',\n",
       "  'quem',\n",
       "  'unum',\n",
       "  'nostrae',\n",
       "  'civitatis',\n",
       "  'et',\n",
       "  'ingenio',\n",
       "  'et',\n",
       "  'iustitia',\n",
       "  'praestantissimum',\n",
       "  'audeo',\n",
       "  'dicere',\n",
       "  '.'],\n",
       " ['Sed', 'de', 'hoc', 'alias', ';', 'nunc', 'redeo', 'ad', 'augurem', '.'],\n",
       " ['[',\n",
       "  '2',\n",
       "  ']',\n",
       "  'Cum',\n",
       "  'saepe',\n",
       "  'multa',\n",
       "  ',',\n",
       "  'tum',\n",
       "  'memini',\n",
       "  'domi',\n",
       "  'in',\n",
       "  'hemicyclio',\n",
       "  'sedentem',\n",
       "  ',',\n",
       "  'ut',\n",
       "  'solebat',\n",
       "  ',',\n",
       "  'cum',\n",
       "  'et',\n",
       "  'ego',\n",
       "  'essem',\n",
       "  'una',\n",
       "  'et',\n",
       "  'pauci',\n",
       "  'admodum',\n",
       "  'familiares',\n",
       "  ',',\n",
       "  'in',\n",
       "  'eum',\n",
       "  'sermonem',\n",
       "  'illum',\n",
       "  'incidere',\n",
       "  'qui',\n",
       "  'tum',\n",
       "  'forte',\n",
       "  'multis',\n",
       "  'erat',\n",
       "  'in',\n",
       "  'ore',\n",
       "  '.'],\n",
       " ['Meministi',\n",
       "  'enim',\n",
       "  'profecto',\n",
       "  ',',\n",
       "  'Attice',\n",
       "  ',',\n",
       "  'et',\n",
       "  'eo',\n",
       "  'magis',\n",
       "  ',',\n",
       "  'quod',\n",
       "  'P.',\n",
       "  'Sulpicio',\n",
       "  'utebare',\n",
       "  'multum',\n",
       "  ',',\n",
       "  'cum',\n",
       "  'is',\n",
       "  'tribunus',\n",
       "  'plebis',\n",
       "  'capitali',\n",
       "  'odio',\n",
       "  'a',\n",
       "  'Q.',\n",
       "  'Pompeio',\n",
       "  ',',\n",
       "  'qui',\n",
       "  'tum',\n",
       "  'erat',\n",
       "  'consul',\n",
       "  ',',\n",
       "  'dissideret',\n",
       "  ',',\n",
       "  'cum',\n",
       "  'quo',\n",
       "  'coniunctissime',\n",
       "  'et',\n",
       "  'amantissime',\n",
       "  'vixerat',\n",
       "  ',',\n",
       "  'quanta',\n",
       "  'esset',\n",
       "  'hominum',\n",
       "  'vel',\n",
       "  'admiratio',\n",
       "  'vel',\n",
       "  'querella',\n",
       "  '.'],\n",
       " ['[',\n",
       "  '3',\n",
       "  ']',\n",
       "  'Itaque',\n",
       "  'tum',\n",
       "  'Scaevola',\n",
       "  'cum',\n",
       "  'in',\n",
       "  'eam',\n",
       "  'ipsam',\n",
       "  'mentionem',\n",
       "  'incidisset',\n",
       "  ',',\n",
       "  'exposuit',\n",
       "  'nobis',\n",
       "  'sermonem',\n",
       "  'Laeli',\n",
       "  'de',\n",
       "  'amicitia',\n",
       "  'habitum',\n",
       "  'ab',\n",
       "  'illo',\n",
       "  'cum',\n",
       "  'se',\n",
       "  'et',\n",
       "  'cum',\n",
       "  'altero',\n",
       "  'genero',\n",
       "  ',',\n",
       "  'C.',\n",
       "  'Fannio',\n",
       "  'Marci',\n",
       "  'filio',\n",
       "  ',',\n",
       "  'paucis',\n",
       "  'diebus',\n",
       "  'post',\n",
       "  'mortem',\n",
       "  'Africani',\n",
       "  '.'],\n",
       " ['Eius',\n",
       "  'disputationis',\n",
       "  'sententias',\n",
       "  'memoriae',\n",
       "  'mandavi',\n",
       "  ',',\n",
       "  'quas',\n",
       "  'hoc',\n",
       "  'libro',\n",
       "  'exposui',\n",
       "  'arbitratu',\n",
       "  'meo',\n",
       "  ';',\n",
       "  'quasi',\n",
       "  'enim',\n",
       "  'ipsos',\n",
       "  'induxi',\n",
       "  'loquentes',\n",
       "  ',',\n",
       "  'ne',\n",
       "  \"'inquam\",\n",
       "  \"'\",\n",
       "  'et',\n",
       "  \"'inquit\",\n",
       "  \"'\",\n",
       "  'saepius',\n",
       "  'interponeretur',\n",
       "  ',',\n",
       "  'atque',\n",
       "  'ut',\n",
       "  'tamquam',\n",
       "  'a',\n",
       "  'praesentibus',\n",
       "  'coram',\n",
       "  'haberi',\n",
       "  'sermo',\n",
       "  'videretur',\n",
       "  '.']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_amicitia_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making sense of PoS tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/francescomambrini/gAGDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.expanduser('~/Documents/gAGDT/'))\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treebanks import Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treebanks.Morph"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pos_tag = 'T-SRPPMN-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-33b0c63b1b73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMorph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_pos_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/gAGDT/treebanks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tag: {} is invalid\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'T'"
     ]
    }
   ],
   "source": [
    "Morph(my_pos_tag).full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'case': 'nominative',\n",
       " 'degree': '-',\n",
       " 'gender': 'masculine',\n",
       " 'mood': 'participle',\n",
       " 'number': 'singular',\n",
       " 'person': '-',\n",
       " 'pos': 'verb',\n",
       " 'tense': 'perfect',\n",
       " 'voice': 'passive'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Morph(my_pos_tag.lower()).full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnt_output = tagger.tag_tnt(\" \".join([str(w) for w in amicitia_words[100:150]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('91', 'Unk'),\n",
       " ('92', 'Unk'),\n",
       " ('93', 'Unk'),\n",
       " ('94', 'Unk'),\n",
       " ('95', 'Unk'),\n",
       " ('96', 'Unk'),\n",
       " ('97', 'Unk'),\n",
       " ('98', 'Unk'),\n",
       " ('99', 'Unk'),\n",
       " ('100', 'Unk')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnt_output[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ U-------- {'pos': 'punctuation', 'person': '-', 'number': '-', 'tense': '-', 'mood': '-', 'voice': '-', 'gender': '-', 'case': '-', 'degree': '-'}\n",
      "] U-------- {'pos': 'punctuation', 'person': '-', 'number': '-', 'tense': '-', 'mood': '-', 'voice': '-', 'gender': '-', 'case': '-', 'degree': '-'}\n",
      ". U-------- {'pos': 'punctuation', 'person': '-', 'number': '-', 'tense': '-', 'mood': '-', 'voice': '-', 'gender': '-', 'case': '-', 'degree': '-'}\n",
      "multa A-P---NA- {'pos': 'adjective', 'person': '-', 'number': 'plural', 'tense': '-', 'mood': '-', 'voice': '-', 'gender': 'neuter', 'case': 'accusative', 'degree': '-'}\n",
      "narrare V--PNA--- {'pos': 'verb', 'person': '-', 'number': '-', 'tense': 'present', 'mood': 'infinitive', 'voice': 'active', 'gender': '-', 'case': '-', 'degree': '-'}\n",
      "de R-------- {'pos': 'preposition', 'person': '-', 'number': '-', 'tense': '-', 'mood': '-', 'voice': '-', 'gender': '-', 'case': '-', 'degree': '-'}\n",
      ". U-------- {'pos': 'punctuation', 'person': '-', 'number': '-', 'tense': '-', 'mood': '-', 'voice': '-', 'gender': '-', 'case': '-', 'degree': '-'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-3aa08690bd09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_tag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtnt_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpos_tag\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Unk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMorph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/gAGDT/treebanks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgender\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'b'"
     ]
    }
   ],
   "source": [
    "for token, pos_tag in tnt_output:\n",
    "    if pos_tag != \"Unk\":\n",
    "        print(token, pos_tag, Morph(pos_tag.lower()).full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \t punctuation\n",
      "\n",
      "] \t punctuation\n",
      "\n",
      ". \t punctuation\n",
      "\n",
      "multa \t adjective\n",
      "\n",
      "narrare \t verb\n",
      "\n",
      "de \t preposition\n",
      "\n",
      ". \t punctuation\n",
      "\n",
      "Expanded form for A-S---NB- not available (error: 'b')\n",
      "\n",
      "et \t conjunction\n",
      "\n",
      "solebat \t verb\n",
      "\n",
      "nec \t conjunction\n",
      "\n",
      "illum \t pron\n",
      "\n",
      "in \t preposition\n",
      "\n",
      "Expanded form for A-S---MB- not available (error: 'b')\n",
      "\n",
      "Expanded form for N-S---MB- not available (error: 'b')\n",
      "\n",
      "appellare \t verb\n",
      "\n",
      "ego \t pron\n",
      "\n",
      "autem \t conjunction\n",
      "\n",
      "a \t preposition\n",
      "\n",
      "Expanded form for N-S---MB- not available (error: 'b')\n",
      "\n",
      "ita \t adverb\n",
      "\n",
      "eram \t verb\n",
      "\n",
      "deductus \t verb\n",
      "\n",
      "ad \t preposition\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token, pos_tag in tnt_output:\n",
    "    if pos_tag != \"Unk\":\n",
    "        try:\n",
    "            pos_info = Morph(pos_tag.lower()).full\n",
    "            print(\"{} \\t {}\\n\".format(token, pos_info[\"pos\"]))\n",
    "        except Exception as e:\n",
    "            print(\"Expanded form for {} not available (error: {})\\n\".format(pos_tag, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TreeTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TreeTagger` is available as a command line tool, but there are ways of calling it from within Python code.\n",
    "\n",
    "The code below uses a *python wrapper*, namely a couple of python classes/methods that exposes `TreeTagger`'s functionalities via Python objects/methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treetagger import TreeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TREETAGGER_HOME'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-676c74edce9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TREETAGGER_HOME\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/bin/../lib/python3.6/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TREETAGGER_HOME'"
     ]
    }
   ],
   "source": [
    "os.environ[\"TREETAGGER_HOME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TREETAGGER_HOME\"] = os.path.expanduser('~/tree-tagger/cmd/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rromanello/tree-tagger/cmd/'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"TREETAGGER_HOME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TreeTagger(language=\"latin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<treetagger.TreeTagger at 0x10f2bb518>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cogito', 'V:IMP', 'cogo'],\n",
       " ['ergo', 'ADV', 'ergo'],\n",
       " ['sum', 'ESSE:IND', 'sum']]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.tag(\"Cogito ergo sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['91', 'ADJ:NUM', '@card@'],\n",
       " ['92', 'ADJ:NUM', '@card@'],\n",
       " ['93', 'ADJ:NUM', '@card@'],\n",
       " ['94', 'ADJ:NUM', '@card@'],\n",
       " ['95', 'ADJ:NUM', '@card@'],\n",
       " ['96', 'ADJ:NUM', '@card@'],\n",
       " ['97', 'ADJ:NUM', '@card@'],\n",
       " ['98', 'ADJ:NUM', '@card@'],\n",
       " ['99', 'ADJ:NUM', '@card@'],\n",
       " ['100', 'ADJ:NUM', '@card@'],\n",
       " ['101', 'ADJ:NUM', '@card@'],\n",
       " ['102', 'ADJ:NUM', '@card@'],\n",
       " ['103', 'ADJ:NUM', '@card@'],\n",
       " ['104', 'ADJ:NUM', '@card@'],\n",
       " ['[', 'PUN', '['],\n",
       " ['1', 'ADJ:NUM', '@card@'],\n",
       " [']', 'PUN', ']'],\n",
       " ['Q.', 'ABBR', 'Q.'],\n",
       " ['Mucius', 'ADJ', '<unknown>'],\n",
       " ['augur', 'N:nom', 'augur'],\n",
       " ['multa', 'ADJ', 'multus'],\n",
       " ['narrare', 'V:INF', 'narro'],\n",
       " ['de', 'PREP', 'de'],\n",
       " ['C.', 'ABBR', 'C.'],\n",
       " ['Laelio', 'N:abl', '<unknown>'],\n",
       " ['socero', 'N:abl', 'socer'],\n",
       " ['suo', 'POSS', 'suus'],\n",
       " ['memoriter', 'ADV', 'memoriter'],\n",
       " ['et', 'CC', 'et'],\n",
       " ['iucunde', 'ADJ', '<unknown>'],\n",
       " ['solebat', 'V:IND', 'soleo'],\n",
       " ['nec', 'CC', 'nec'],\n",
       " ['dubitare', 'V:INF', 'dubito'],\n",
       " ['illum', 'DIMOS', 'ille'],\n",
       " ['in', 'PREP', 'in'],\n",
       " ['omni', 'PRON', 'omnis'],\n",
       " ['sermone', 'N:abl', 'sermo'],\n",
       " ['appellare', 'V:INF', 'appello'],\n",
       " ['sapientem', 'N:acc', 'sapiens'],\n",
       " [';', 'SENT', ';'],\n",
       " ['ego', 'PRON', 'ego'],\n",
       " ['autem', 'ADV', 'autem'],\n",
       " ['a', 'PREP', 'a'],\n",
       " ['patre', 'N:abl', 'pater'],\n",
       " ['ita', 'ADV', 'ita'],\n",
       " ['eram', 'ESSE:IND', 'sum'],\n",
       " ['deductus', 'V:PTC:nom', 'deduco'],\n",
       " ['ad', 'PREP', 'ad'],\n",
       " ['Scaevolam', 'NPR', '<unknown>'],\n",
       " ['sumpta', 'V:PTC:nom', 'sumo']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.tag(amicitia_words[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLTK taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "grk_corpus_importer.import_corpus(\"greek_models_cltk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.tag.pos import POSTag\n",
    "tagger = POSTag('greek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Œ∏ŒµŒø·Ω∫œÇ', 'N-P---MA-'),\n",
       " ('Œº·Ω≤ŒΩ', 'G--------'),\n",
       " ('Œ±·º∞œÑ·ø∂', 'V1SPIA---'),\n",
       " ('œÑ·ø∂ŒΩŒ¥', 'P-P---MG-'),\n",
       " ('·æΩ', None),\n",
       " ('·ºÄœÄŒ±ŒªŒªŒ±Œ≥·Ω¥ŒΩ', 'N-S---FA-'),\n",
       " ('œÄœåŒΩœâŒΩ', 'N-P---MG-'),\n",
       " ('œÜœÅŒøœÖœÅ·æ∂œÇ', 'N-S---FG-'),\n",
       " ('·ºêœÑŒµŒØŒ±œÇ', 'A-S---FG-'),\n",
       " ('Œº·øÜŒ∫ŒøœÇ', 'N-S---NA-')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag_ngram_123_backoff('Œ∏ŒµŒø·Ω∫œÇ Œº·Ω≤ŒΩ Œ±·º∞œÑ·ø∂ œÑ·ø∂ŒΩŒ¥·æΩ ·ºÄœÄŒ±ŒªŒªŒ±Œ≥·Ω¥ŒΩ œÄœåŒΩœâŒΩ œÜœÅŒøœÖœÅ·æ∂œÇ ·ºêœÑŒµŒØŒ±œÇ Œº·øÜŒ∫ŒøœÇ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Œ∏ŒµŒø·Ω∫œÇ', 'N-P---MA-'),\n",
       " ('Œº·Ω≤ŒΩ', 'G--------'),\n",
       " ('Œ±·º∞œÑ·ø∂', 'V1SPIA---'),\n",
       " ('œÑ·ø∂ŒΩŒ¥', 'P-P---NG-'),\n",
       " ('·æΩ', 'Unk'),\n",
       " ('·ºÄœÄŒ±ŒªŒªŒ±Œ≥·Ω¥ŒΩ', 'N-S---FA-'),\n",
       " ('œÄœåŒΩœâŒΩ', 'N-P---MG-'),\n",
       " ('œÜœÅŒøœÖœÅ·æ∂œÇ', 'N-S---FG-'),\n",
       " ('·ºêœÑŒµŒØŒ±œÇ', 'A-S---FG-'),\n",
       " ('Œº·øÜŒ∫ŒøœÇ', 'N-S---NA-')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag_tnt('Œ∏ŒµŒø·Ω∫œÇ Œº·Ω≤ŒΩ Œ±·º∞œÑ·ø∂ œÑ·ø∂ŒΩŒ¥·æΩ ·ºÄœÄŒ±ŒªŒªŒ±Œ≥·Ω¥ŒΩ œÄœåŒΩœâŒΩ œÜœÅŒøœÖœÅ·æ∂œÇ ·ºêœÑŒµŒØŒ±œÇ Œº·øÜŒ∫ŒøœÇ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small detour: importing a Greek corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Is there a handy way to import an Ancient Greek corpus as we did for Latin?\n",
    "\n",
    "**A**: not quite (yet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step: convert the Perseus data (TEI/XML) into plain text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 40/61 [02:26<01:16,  3.66s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-19d991bc1be6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mbeta_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleach\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0ma_replacer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplacer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0municode_converted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_replacer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;31m#print(unicode_converted)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0municode_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcltk_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/greek/text/perseus_unicode/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/cltk/corpus/greek/beta_to_unicode.py\u001b[0m in \u001b[0;36mbeta_code\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpattern2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0;31m# remove third run, if punct list not used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpattern3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# my modified version of https://github.com/cltk/greek_text_perseus/blob/master/perseus_compiler.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import bleach\n",
    "#from cltk.corpus.classical_greek.replacer import Replacer\n",
    "from cltk.corpus.greek.beta_to_unicode import Replacer\n",
    "\n",
    "\n",
    "home = os.path.expanduser('~')\n",
    "cltk_path = os.path.join(home, 'cltk_data')\n",
    "#print(cltk_path)\n",
    "perseus_root = cltk_path + '/greek/text/greek_text_perseus/'\n",
    "#print(perseus_root)\n",
    "ignore = [\n",
    "    '.git',\n",
    "    'LICENSE.md',\n",
    "    'README.md',\n",
    "    'cltk_json',\n",
    "    'json',\n",
    "    'perseus_compiler.py'\n",
    "]\n",
    "authors = [d for d in os.listdir(perseus_root) if d not in ignore]\n",
    "\n",
    "for author in tqdm(authors):\n",
    "    texts = os.listdir(perseus_root + author + '/opensource')\n",
    "    for text in texts:\n",
    "        text_match = re.match(r'.*_gk.xml', text)\n",
    "        if text_match:\n",
    "            gk_file = text_match.group()\n",
    "            txt_file = perseus_root + author + '/opensource/' + gk_file\n",
    "            with open(txt_file) as gk:\n",
    "                html = gk.read()\n",
    "                beta_code = bleach.clean(html, strip=True).upper()\n",
    "                a_replacer = Replacer()\n",
    "                unicode_converted = a_replacer.beta_code(beta_code)\n",
    "                #print(unicode_converted)\n",
    "                unicode_root = cltk_path + '/greek/text/perseus_unicode/'\n",
    "                unic_pres = os.path.isdir(unicode_root)\n",
    "                if unic_pres is True:\n",
    "                    pass\n",
    "                else:\n",
    "                    os.mkdir(unicode_root)\n",
    "                author_path = unicode_root + author\n",
    "                author_path_pres = os.path.isdir(author_path)\n",
    "                if author_path_pres is True:\n",
    "                    pass\n",
    "                else:\n",
    "                    os.mkdir(author_path)\n",
    "                gk_file_txt = os.path.splitext(gk_file)[0] + '.txt'\n",
    "                uni_write = author_path + '/' + gk_file_txt\n",
    "                #print(uni_write)\n",
    "                with open(uni_write, 'w') as uni_write:\n",
    "                    uni_write.write(unicode_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
    "from cltk.tokenize.sentence import TokenizeSentence\n",
    "from cltk.tokenize.word import WordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "agrk_word_tokenizer = WordTokenizer('greek')\n",
    "agrk_sentence_tokenizer = TokenizeSentence(\"greek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cltk_path = os.path.expanduser('~/cltk_data')\n",
    "try:\n",
    "    perseusgreek = PlaintextCorpusReader(\n",
    "        cltk_path + '/greek/text/perseus_unicode/', \n",
    "        '.*\\.txt',\n",
    "        word_tokenizer=agrk_word_tokenizer, \n",
    "        sent_tokenizer=agrk_sentence_tokenizer, \n",
    "        encoding='utf-8'\n",
    "    )    \n",
    "    pass\n",
    "except IOError as e:\n",
    "    #pass\n",
    "    print(\"Corpus not found. Please check that the Latin Library is installed in CLTK_DATA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aeschines/aeschin_gk.txt',\n",
       " 'Aeschylus/aesch.ag_gk.txt',\n",
       " 'Aeschylus/aesch.eum_gk.txt',\n",
       " 'Aeschylus/aesch.lib_gk.txt',\n",
       " 'Aeschylus/aesch.pb_gk.txt',\n",
       " 'Aeschylus/aesch.pers_gk.txt',\n",
       " 'Aeschylus/aesch.seven_gk.txt',\n",
       " 'Aeschylus/aesch.supp_gk.txt',\n",
       " 'Andocides/andoc_gk.txt',\n",
       " 'Anth/01_gk.txt',\n",
       " 'Anth/02_gk.txt',\n",
       " 'Anth/03_gk.txt',\n",
       " 'Anth/04_gk.txt',\n",
       " 'Anth/05_gk.txt',\n",
       " 'Apollodorus/apollod_gk.txt',\n",
       " 'Apollonius/argo_gk.txt',\n",
       " 'Appian/appian.cw_gk.txt',\n",
       " 'Appian/appian.fw_gk.txt',\n",
       " 'Aretaeus/aret_gk.txt',\n",
       " 'Aristides/aristid.orat_gk.txt',\n",
       " 'Aristides/aristid.rhet_gk.txt',\n",
       " 'Aristophanes/aristoph.ach_gk.txt',\n",
       " 'Aristophanes/aristoph.birds_gk.txt',\n",
       " 'Aristophanes/aristoph.cl_gk.txt',\n",
       " 'Aristophanes/aristoph.eccl_gk.txt',\n",
       " 'Aristophanes/aristoph.frogs_gk.txt',\n",
       " 'Aristophanes/aristoph.kn_gk.txt',\n",
       " 'Aristophanes/aristoph.lys_gk.txt',\n",
       " 'Aristophanes/aristoph.peace_gk.txt',\n",
       " 'Aristophanes/aristoph.pl_gk.txt',\n",
       " 'Aristophanes/aristoph.thes_gk.txt',\n",
       " 'Aristophanes/aristoph.wasps_gk.txt',\n",
       " 'Aristotle/aristot.ath.pol_gk.txt',\n",
       " 'Aristotle/aristot.econ_gk.txt',\n",
       " 'Aristotle/aristot.eud.eth_gk.txt',\n",
       " 'Aristotle/aristot.met_gk.txt',\n",
       " 'Aristotle/aristot.nic.eth_gk.txt',\n",
       " 'Aristotle/aristot.pol_gk.txt',\n",
       " 'Aristotle/aristot.rh_gk.txt',\n",
       " 'Aristotle/aristot.vir_gk.txt',\n",
       " 'Arrian/arrian.acies_gk.txt',\n",
       " 'Arrian/arrian.anab_gk.txt',\n",
       " 'Arrian/arrian.cuneg_gk.txt',\n",
       " 'Arrian/arrian.indica_gk.txt',\n",
       " 'Arrian/arrian.periplous_gk.txt',\n",
       " 'Arrian/arrian.tactica_gk.txt',\n",
       " 'Athenaeus/ath01_gk.txt',\n",
       " 'Athenaeus/ath02_gk.txt',\n",
       " 'Athenaeus/ath03_gk.txt',\n",
       " 'Athenaeus/ath04_gk.txt',\n",
       " 'Athenaeus/ath05_gk.txt',\n",
       " 'Athenaeus/ath06_gk.txt',\n",
       " 'Athenaeus/ath07_gk.txt',\n",
       " 'Athenaeus/ath08_gk.txt',\n",
       " 'Athenaeus/ath09_gk.txt',\n",
       " 'Athenaeus/ath10_gk.txt',\n",
       " 'Athenaeus/ath11_gk.txt',\n",
       " 'Athenaeus/ath12_gk.txt',\n",
       " 'Athenaeus/ath13_gk.txt',\n",
       " 'Athenaeus/ath14_gk.txt',\n",
       " 'Athenaeus/ath15_gk.txt',\n",
       " 'Bacchylides/bacchyl_gk.txt',\n",
       " 'Bible/nt_gk.txt',\n",
       " 'Colluthus/colluthus.01_gk.txt',\n",
       " 'Demades/demad_gk.txt',\n",
       " 'Demosthenes/dem01-10_gk.txt',\n",
       " 'Demosthenes/dem11-20_gk.txt',\n",
       " 'Demosthenes/dem21-30_gk.txt',\n",
       " 'Demosthenes/dem31-40_gk.txt',\n",
       " 'Demosthenes/dem41-50_gk.txt',\n",
       " 'Demosthenes/dem51-61_gk.txt',\n",
       " 'Dinarchus/din_gk.txt',\n",
       " 'DioChrys/diochr01_gk.txt',\n",
       " 'DioChrys/diochr02_gk.txt',\n",
       " 'Diodorus/diod.hist01-05_gk.txt',\n",
       " 'Diodorus/diod.hist18-20_gk.txt',\n",
       " 'Diodorus/diod_gk.txt',\n",
       " 'Diogenes/dl_gk.txt',\n",
       " 'Dionysius/dh.002_gk.txt',\n",
       " 'Dionysius/dh.003_gk.txt',\n",
       " 'Dionysius/dh.004_gk.txt',\n",
       " 'Dionysius/dh.005_gk.txt',\n",
       " 'Dionysius/dh.006_gk.txt',\n",
       " 'Dionysius/dh.007_gk.txt',\n",
       " 'Dionysius/dh.008_gk.txt',\n",
       " 'Dionysius/dh.009_gk.txt',\n",
       " 'Dionysius/dh.010_gk.txt',\n",
       " 'Dionysius/dh.011_gk.txt',\n",
       " 'Dionysius/dh.012_gk.txt',\n",
       " 'Dionysius/dh.015_gk.txt',\n",
       " 'Dionysius/dh.hist01_gk.txt',\n",
       " 'Dionysius/dh.hist02_gk.txt',\n",
       " 'Dionysius/dh.hist03_gk.txt',\n",
       " 'Dionysius/dh.hist04_gk.txt',\n",
       " 'Elegy/1_gk.txt',\n",
       " 'Elegy/2_gk.txt',\n",
       " 'Epictetus/epictetus_gk.txt',\n",
       " 'Euclid/euc.elem_gk.txt',\n",
       " 'Euripides/eur.ba_gk.txt',\n",
       " 'Euripides/eur.el_gk.txt',\n",
       " 'Euripides/eur.hec_gk.txt',\n",
       " 'Euripides/eur.hel_gk.txt',\n",
       " 'Euripides/eur.her_gk.txt',\n",
       " 'Euripides/eur.ia_gk.txt',\n",
       " 'Euripides/eur.ion_gk.txt',\n",
       " 'Euripides/eur.it_gk.txt',\n",
       " 'Euripides/eur.orest_gk.txt',\n",
       " 'Euripides/eur.phoen_gk.txt',\n",
       " 'Euripides/eur.rh_gk.txt',\n",
       " 'Euripides/eur.supp_gk.txt',\n",
       " 'Euripides/eur.tro_gk.txt',\n",
       " 'Galen/gal.nat.fac_gk.txt',\n",
       " 'Herodotus/hdt_gk.txt',\n",
       " 'Hesiod/hes.sh_gk.txt',\n",
       " 'Hesiod/hes.th_gk.txt',\n",
       " 'Hesiod/hes.wd_gk.txt',\n",
       " 'Hippocrates/hp.jones_gk.txt',\n",
       " 'Hippocrates/hp.littre_gk.txt',\n",
       " 'Homer/hom.il_gk.txt',\n",
       " 'Homer/hom.od_gk.txt',\n",
       " 'Homeric_Hymns/hh_gk.txt',\n",
       " 'Hyperides/hyp_gk.txt',\n",
       " 'Josephus/j.aj_gk.txt',\n",
       " 'Josephus/j.ap_gk.txt',\n",
       " 'Josephus/j.bj_gk.txt',\n",
       " 'Josephus/j.vit_gk.txt',\n",
       " 'Lucian/01_gk.txt',\n",
       " 'Lucian/02_gk.txt',\n",
       " 'Lucian/03_gk.txt',\n",
       " 'Lucian/04_gk.txt',\n",
       " 'Lucian/05_gk.txt',\n",
       " 'Lucian/06_gk.txt',\n",
       " 'Lucian/07_gk.txt',\n",
       " 'Lucian/08_gk.txt',\n",
       " 'Lucian/09_gk.txt',\n",
       " 'Lucian/10_gk.txt',\n",
       " 'Lucian/11_gk.txt',\n",
       " 'Lucian/12_gk.txt',\n",
       " 'Lucian/13_gk.txt',\n",
       " 'Lucian/14_gk.txt',\n",
       " 'Lucian/15_gk.txt',\n",
       " 'Lucian/16_gk.txt',\n",
       " 'Lucian/17_gk.txt',\n",
       " 'Lucian/18_gk.txt',\n",
       " 'Lucian/19_gk.txt',\n",
       " 'Lucian/20_gk.txt',\n",
       " 'Lucian/21_gk.txt',\n",
       " 'Lucian/22_gk.txt',\n",
       " 'Lucian/23_gk.txt',\n",
       " 'Lucian/24_gk.txt',\n",
       " 'Lucian/25_gk.txt',\n",
       " 'Lucian/26_gk.txt',\n",
       " 'Lucian/27_gk.txt',\n",
       " 'Lucian/28_gk.txt',\n",
       " 'Lucian/29_gk.txt',\n",
       " 'Lucian/30_gk.txt',\n",
       " 'Lucian/31_gk.txt',\n",
       " 'Lucian/32_gk.txt',\n",
       " 'Lucian/33_gk.txt',\n",
       " 'Lucian/34_gk.txt',\n",
       " 'Lucian/35_gk.txt',\n",
       " 'Lucian/36_gk.txt',\n",
       " 'Lucian/37_gk.txt',\n",
       " 'Lucian/38_gk.txt',\n",
       " 'Lucian/39_gk.txt',\n",
       " 'Lucian/40_gk.txt',\n",
       " 'Lucian/41_gk.txt',\n",
       " 'Lucian/42_gk.txt',\n",
       " 'Lucian/43_gk.txt',\n",
       " 'Lucian/44_gk.txt',\n",
       " 'Lucian/45_gk.txt',\n",
       " 'Lucian/46_gk.txt',\n",
       " 'Lucian/47_gk.txt',\n",
       " 'Lucian/48_gk.txt',\n",
       " 'Lucian/49_gk.txt',\n",
       " 'Lucian/50_gk.txt',\n",
       " 'Lucian/51_gk.txt',\n",
       " 'Lucian/52_gk.txt',\n",
       " 'Lucian/53_gk.txt',\n",
       " 'Lucian/54_gk.txt',\n",
       " 'Lucian/55_gk.txt',\n",
       " 'Lucian/56_gk.txt',\n",
       " 'Lucian/57_gk.txt',\n",
       " 'Lucian/58_gk.txt',\n",
       " 'Lucian/59_gk.txt',\n",
       " 'Lucian/60_gk.txt',\n",
       " 'Lucian/61_gk.txt',\n",
       " 'Lucian/62_gk.txt',\n",
       " 'Lucian/63_gk.txt',\n",
       " 'Lucian/64_gk.txt',\n",
       " 'Lucian/65_gk.txt',\n",
       " 'Lucian/66_gk.txt',\n",
       " 'Lucian/67_gk.txt',\n",
       " 'Lucian/68_gk.txt',\n",
       " 'Lucian/69_gk.txt',\n",
       " 'Lucian/70_gk.txt',\n",
       " 'Lucian/71_gk.txt',\n",
       " 'Lycurgus/lyc_gk.txt',\n",
       " 'Lysias/lys_gk.txt',\n",
       " 'Pausanias/paus_gk.txt',\n",
       " 'Pindar/pind_gk.txt',\n",
       " 'Plato/plat.l_gk.txt',\n",
       " 'Plato/plat.laws_gk.txt',\n",
       " 'Plato/plat.rep_gk.txt',\n",
       " 'Plato/plat.tet1_gk.txt',\n",
       " 'Plato/plat.tet2_gk.txt',\n",
       " 'Plato/plat.tet3_gk.txt',\n",
       " 'Plato/plat.tet45_gk.txt',\n",
       " 'Plato/plat.tet6_gk.txt',\n",
       " 'Plato/plat.tet789_gk.txt',\n",
       " 'Plutarch/plut.0094.002_teubner_gk.txt',\n",
       " 'Plutarch/plut.0094.003_teubner_gk.txt',\n",
       " 'Plutarch/plut.067_teubner_gk.txt',\n",
       " 'Plutarch/plut.068_teubner_gk.txt',\n",
       " 'Plutarch/plut.069_teubner_gk.txt',\n",
       " 'Plutarch/plut.070_teubner_gk.txt',\n",
       " 'Plutarch/plut.071_teubner_gk.txt',\n",
       " 'Plutarch/plut.072_teubner_gk.txt',\n",
       " 'Plutarch/plut.073_teubner_gk.txt',\n",
       " 'Plutarch/plut.074_teubner_gk.txt',\n",
       " 'Plutarch/plut.075_teubner_gk.txt',\n",
       " 'Plutarch/plut.076_teubner_gk.txt',\n",
       " 'Plutarch/plut.077_teubner_gk.txt',\n",
       " 'Plutarch/plut.078_teubner_gk.txt',\n",
       " 'Plutarch/plut.079_teubner_gk.txt',\n",
       " 'Plutarch/plut.080_teubner_gk.txt',\n",
       " 'Plutarch/plut.081_loeb_gk.txt',\n",
       " 'Plutarch/plut.081_teubner_gk.txt',\n",
       " 'Plutarch/plut.082_loeb_gk.txt',\n",
       " 'Plutarch/plut.082_teubner_gk.txt',\n",
       " 'Plutarch/plut.082a_loeb_gk.txt',\n",
       " 'Plutarch/plut.082a_teubner_gk.txt',\n",
       " 'Plutarch/plut.082b_loeb_gk.txt',\n",
       " 'Plutarch/plut.082b_teubner_gk.txt',\n",
       " 'Plutarch/plut.083_loeb_gk.txt',\n",
       " 'Plutarch/plut.083_teubner_gk.txt',\n",
       " 'Plutarch/plut.084a_loeb_gk.txt',\n",
       " 'Plutarch/plut.084a_teubner_gk.txt',\n",
       " 'Plutarch/plut.084b_loeb_gk.txt',\n",
       " 'Plutarch/plut.084b_teubner_gk.txt',\n",
       " 'Plutarch/plut.085_loeb_gk.txt',\n",
       " 'Plutarch/plut.085_teubner_gk.txt',\n",
       " 'Plutarch/plut.086_loeb_gk.txt',\n",
       " 'Plutarch/plut.086_teubner_gk.txt',\n",
       " 'Plutarch/plut.087_loeb_gk.txt',\n",
       " 'Plutarch/plut.087_teubner_gk.txt',\n",
       " 'Plutarch/plut.088_loeb_gk.txt',\n",
       " 'Plutarch/plut.088_teubner_gk.txt',\n",
       " 'Plutarch/plut.089_teubner_gk.txt',\n",
       " 'Plutarch/plut.090_teubner_gk.txt',\n",
       " 'Plutarch/plut.091_teubner_gk.txt',\n",
       " 'Plutarch/plut.092_teubner_gk.txt',\n",
       " 'Plutarch/plut.093_loeb_gk.txt',\n",
       " 'Plutarch/plut.093_teubner_gk.txt',\n",
       " 'Plutarch/plut.094_loeb_gk.txt',\n",
       " 'Plutarch/plut.094_teubner_gk.txt',\n",
       " 'Plutarch/plut.095_loeb_gk.txt',\n",
       " 'Plutarch/plut.095_teubner_gk.txt',\n",
       " 'Plutarch/plut.096_loeb_gk.txt',\n",
       " 'Plutarch/plut.096_teubner_gk.txt',\n",
       " 'Plutarch/plut.097_loeb_gk.txt',\n",
       " 'Plutarch/plut.097_teubner_gk.txt',\n",
       " 'Plutarch/plut.098_loeb_gk.txt',\n",
       " 'Plutarch/plut.098_teubner_gk.txt',\n",
       " 'Plutarch/plut.099_loeb_gk.txt',\n",
       " 'Plutarch/plut.099_teubner_gk.txt',\n",
       " 'Plutarch/plut.100_loeb_gk.txt',\n",
       " 'Plutarch/plut.100_teubner_gk.txt',\n",
       " 'Plutarch/plut.101_loeb_gk.txt',\n",
       " 'Plutarch/plut.101_teubner_gk.txt',\n",
       " 'Plutarch/plut.102_loeb_gk.txt',\n",
       " 'Plutarch/plut.102_teubner_gk.txt',\n",
       " 'Plutarch/plut.103_teubner_gk.txt',\n",
       " 'Plutarch/plut.104_teubner_gk.txt',\n",
       " 'Plutarch/plut.105_teubner_gk.txt',\n",
       " 'Plutarch/plut.106_teubner_gk.txt',\n",
       " 'Plutarch/plut.107_teubner_gk.txt',\n",
       " 'Plutarch/plut.108_teubner_gk.txt',\n",
       " 'Plutarch/plut.109_teubner_gk.txt',\n",
       " 'Plutarch/plut.110_teubner_gk.txt',\n",
       " 'Plutarch/plut.111_teubner_gk.txt',\n",
       " 'Plutarch/plut.112_teubner_gk.txt',\n",
       " 'Plutarch/plut.113_teubner_gk.txt',\n",
       " 'Plutarch/plut.114_teubner_gk.txt',\n",
       " 'Plutarch/plut.115_teubner_gk.txt',\n",
       " 'Plutarch/plut.116_teubner_gk.txt',\n",
       " 'Plutarch/plut.117_teubner_gk.txt',\n",
       " 'Plutarch/plut.118_teubner_gk.txt',\n",
       " 'Plutarch/plut.119_teubner_gk.txt',\n",
       " 'Plutarch/plut.120_teubner_gk.txt',\n",
       " 'Plutarch/plut.121_teubner_gk.txt',\n",
       " 'Plutarch/plut.122_teubner_gk.txt',\n",
       " 'Plutarch/plut.123_teubner_gk.txt',\n",
       " 'Plutarch/plut.125_teubner_gk.txt',\n",
       " 'Plutarch/plut.126_teubner_gk.txt',\n",
       " 'Plutarch/plut.127_teubner_gk.txt',\n",
       " 'Plutarch/plut.128_teubner_gk.txt',\n",
       " 'Plutarch/plut.129_teubner_gk.txt',\n",
       " 'Plutarch/plut.130_teubner_gk.txt',\n",
       " 'Plutarch/plut.131_teubner_gk.txt',\n",
       " 'Plutarch/plut.132_teubner_gk.txt',\n",
       " 'Plutarch/plut.133_teubner_gk.txt',\n",
       " 'Plutarch/plut.134_teubner_gk.txt',\n",
       " 'Plutarch/plut.135_teubner_gk.txt',\n",
       " 'Plutarch/plut.136_teubner_gk.txt',\n",
       " 'Plutarch/plut.137_teubner_gk.txt',\n",
       " 'Plutarch/plut.138_teubner_gk.txt',\n",
       " 'Plutarch/plut.139_teubner_gk.txt',\n",
       " 'Plutarch/plut.140_teubner_gk.txt',\n",
       " 'Plutarch/plut.141_teubner_gk.txt',\n",
       " 'Plutarch/plut.aem_gk.txt',\n",
       " 'Plutarch/plut.ages_gk.txt',\n",
       " 'Plutarch/plut.agis_gk.txt',\n",
       " 'Plutarch/plut.alc_gk.txt',\n",
       " 'Plutarch/plut.alex_gk.txt',\n",
       " 'Plutarch/plut.ant_gk.txt',\n",
       " 'Plutarch/plut.arat_gk.txt',\n",
       " 'Plutarch/plut.arist_gk.txt',\n",
       " 'Plutarch/plut.art_gk.txt',\n",
       " 'Plutarch/plut.brut_gk.txt',\n",
       " 'Plutarch/plut.caes_gk.txt',\n",
       " 'Plutarch/plut.cam_gk.txt',\n",
       " 'Plutarch/plut.cat.ma_gk.txt',\n",
       " 'Plutarch/plut.cat.mi_gk.txt',\n",
       " 'Plutarch/plut.cg_gk.txt',\n",
       " 'Plutarch/plut.cic_gk.txt',\n",
       " 'Plutarch/plut.cim_gk.txt',\n",
       " 'Plutarch/plut.cleom_gk.txt',\n",
       " 'Plutarch/plut.comp.ages.pomp_gk.txt',\n",
       " 'Plutarch/plut.comp.agis.cleom.g_gk.txt',\n",
       " 'Plutarch/plut.comp.alc.cor_gk.txt',\n",
       " 'Plutarch/plut.comp.arist.cat.ma_gk.txt',\n",
       " 'Plutarch/plut.comp.dem.cic_gk.txt',\n",
       " 'Plutarch/plut.comp.demetr.ant_gk.txt',\n",
       " 'Plutarch/plut.comp.dio.brut_gk.txt',\n",
       " 'Plutarch/plut.comp.luc.cim_gk.txt',\n",
       " 'Plutarch/plut.comp.lyc.num_gk.txt',\n",
       " 'Plutarch/plut.comp.lys.sull_gk.txt',\n",
       " 'Plutarch/plut.comp.nic.crass_gk.txt',\n",
       " 'Plutarch/plut.comp.pel.marc_gk.txt',\n",
       " 'Plutarch/plut.comp.per.fab_gk.txt',\n",
       " 'Plutarch/plut.comp.phil.flam_gk.txt',\n",
       " 'Plutarch/plut.comp.sert.eum_gk.txt',\n",
       " 'Plutarch/plut.comp.sol.publ_gk.txt',\n",
       " 'Plutarch/plut.comp.thes.rom_gk.txt',\n",
       " 'Plutarch/plut.comp.tim.aem_gk.txt',\n",
       " 'Plutarch/plut.cor_gk.txt',\n",
       " 'Plutarch/plut.crass_gk.txt',\n",
       " 'Plutarch/plut.dem_gk.txt',\n",
       " 'Plutarch/plut.demetr_gk.txt',\n",
       " 'Plutarch/plut.dio_gk.txt',\n",
       " 'Plutarch/plut.eum_gk.txt',\n",
       " 'Plutarch/plut.fab_gk.txt',\n",
       " 'Plutarch/plut.flam_gk.txt',\n",
       " 'Plutarch/plut.gal_gk.txt',\n",
       " 'Plutarch/plut.luc_gk.txt',\n",
       " 'Plutarch/plut.lyc_gk.txt',\n",
       " 'Plutarch/plut.lys_gk.txt',\n",
       " 'Plutarch/plut.mar_gk.txt',\n",
       " 'Plutarch/plut.marc_gk.txt',\n",
       " 'Plutarch/plut.nic_gk.txt',\n",
       " 'Plutarch/plut.num_gk.txt',\n",
       " 'Plutarch/plut.oth_gk.txt',\n",
       " 'Plutarch/plut.pel_gk.txt',\n",
       " 'Plutarch/plut.per_gk.txt',\n",
       " 'Plutarch/plut.phil_gk.txt',\n",
       " 'Plutarch/plut.phoc_gk.txt',\n",
       " 'Plutarch/plut.pomp_gk.txt',\n",
       " 'Plutarch/plut.publ_gk.txt',\n",
       " 'Plutarch/plut.pyrrh_gk.txt',\n",
       " 'Plutarch/plut.rom_gk.txt',\n",
       " 'Plutarch/plut.sert_gk.txt',\n",
       " 'Plutarch/plut.sol_gk.txt',\n",
       " 'Plutarch/plut.sull_gk.txt',\n",
       " 'Plutarch/plut.tg_gk.txt',\n",
       " 'Plutarch/plut.them_gk.txt',\n",
       " 'Plutarch/plut.thes_gk.txt',\n",
       " 'Plutarch/plut.tim_gk.txt',\n",
       " 'Polybius/hist_gk.txt',\n",
       " 'Sophocles/soph.aj_gk.txt',\n",
       " 'Sophocles/soph.ant_gk.txt',\n",
       " 'Sophocles/soph.el_gk.txt',\n",
       " 'Sophocles/soph.ich_gk.txt',\n",
       " 'Sophocles/soph.oc_gk.txt',\n",
       " 'Sophocles/soph.ot_gk.txt',\n",
       " 'Sophocles/soph.phil_gk.txt',\n",
       " 'Sophocles/soph.trach_gk.txt',\n",
       " 'Strabo/strab_gk.txt',\n",
       " 'Theocritus/idylls_gk.txt',\n",
       " 'Theophrastus/char_gk.txt',\n",
       " 'Xenophon/xen.anab_gk.txt',\n",
       " 'Xenophon/xen.cyrop_gk.txt',\n",
       " 'Xenophon/xen.hell_gk.txt',\n",
       " 'Xenophon/xen.mem_gk.txt',\n",
       " 'Xenophon/xen.opuscula_gk.txt',\n",
       " 'Xenophon/xen.socratalia_gk.txt']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perseusgreek.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = perseusgreek.words('Aristophanes/aristoph.birds_gk.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_sentences = perseusgreek.sents('Aristophanes/aristoph.birds_gk.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['%œÄŒµœÅœÉŒ¥œÅŒ±ŒºŒ±', ';', ']', '&', 'Œ≥œÑ', ';'],\n",
       " ['Œ≤ŒπœÅŒ¥œÉ', 'ŒºŒ±ŒæŒ∑ŒπŒΩŒµ', 'œÅŒµŒ±Œ¥Œ±Œ≤ŒªŒµ', 'œÑŒµœáœÑ', 'Œ±œÅŒπœÉœÑŒøœÄŒ∑Œ±ŒΩŒµœÉ', 'œÜ.œâ', '.']]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds_sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['·ºêœÄŒ≠Œ≥ŒµŒπœÅŒøŒΩ',\n",
       " 'Œ±·ΩêœÑœåŒΩ',\n",
       " '.',\n",
       " 'ŒòŒµœÅŒ¨œÄœâŒΩ',\n",
       " '·ºúœÄŒøœÄŒøœÉ',\n",
       " 'Œø·º∂Œ¥Œ±',\n",
       " 'Œº·Ω≤ŒΩ',\n",
       " 'œÉŒ±œÜ·ø∂œÉ',\n",
       " '·ΩÖœÑŒπ',\n",
       " '·ºÄœáŒ∏Œ≠œÉŒµœÑŒ±Œπ',\n",
       " ',',\n",
       " 'œÉœÜ·ø∑ŒΩ',\n",
       " 'Œ¥‚Äô',\n",
       " 'Œ±·ΩêœÑ·Ω∏ŒΩ',\n",
       " 'Œø·ΩïŒΩŒµŒ∫‚Äô',\n",
       " '·ºêœÄŒµŒ≥ŒµœÅ·ø∂',\n",
       " '.',\n",
       " 'Œ†ŒπœÉŒ∏Œ≠œÑŒ±ŒπœÅŒøœÉ',\n",
       " 'Œ∫Œ±Œ∫·ø∂œÇ',\n",
       " 'œÉœç',\n",
       " 'Œ≥‚Äô',\n",
       " '·ºÄœÄœåŒªŒø·øê',\n",
       " ',',\n",
       " '·Ω•œÇ',\n",
       " 'Œº‚Äô',\n",
       " '·ºÄœÄŒ≠Œ∫œÑŒµŒπŒΩŒ±œÇ',\n",
       " 'Œ¥Œ≠ŒµŒπ',\n",
       " '.',\n",
       " '·ºòœÖŒµŒªœÄŒØŒ¥Œ∑œÉ',\n",
       " 'Œø·º¥ŒºŒøŒπ',\n",
       " 'Œ∫Œ±Œ∫ŒøŒ¥Œ±ŒØŒºœâŒΩ',\n",
       " 'œá·Ω†',\n",
       " 'Œ∫ŒøŒªŒøŒπœåœÇ',\n",
       " 'ŒºŒø·º¥œáŒµœÑŒ±Œπ',\n",
       " '·ΩëœÄ·Ω∏',\n",
       " 'œÑŒø·ø¶',\n",
       " 'Œ¥Œ≠ŒøœÖœÇ\\\\',\n",
       " '.',\n",
       " 'Œ†ŒπœÉŒ∏Œ≠œÑŒ±ŒπœÅŒøœÉ',\n",
       " '·Ω¶',\n",
       " 'Œ¥ŒµŒπŒªœåœÑŒ±œÑŒøŒΩ',\n",
       " 'œÉ·Ω∫',\n",
       " 'Œ∏Œ∑œÅŒØŒøŒΩ',\n",
       " ',',\n",
       " 'Œ¥ŒµŒØœÉŒ±œÇ',\n",
       " '·ºÄœÜ·øÜŒ∫Œ±œÇ',\n",
       " 'œÑ·Ω∏ŒΩ',\n",
       " 'Œ∫ŒøŒªŒøŒπœåŒΩ',\n",
       " ';',\n",
       " '·ºòœÖŒµŒªœÄŒØŒ¥Œ∑œÉ']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds[1000:1050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(birds[1000:1100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger.tag_tnt(\" \".join(birds[1000:1100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TreeTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TreeTagger for Ancient Greek became available like...yesterday\n",
    "- documentation: http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tagsetdocs.txt\n",
    "- training for anc. greek is work of Alessandro Vatri and Barbara McGillivray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treetagger import TreeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TreeTagger(language=\"ancient-greek-utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['·ºêœÄŒ≠Œ≥ŒµŒπœÅŒøŒΩ', 'verb', '-'],\n",
       " ['Œ±·ΩêœÑœåŒΩ', 'pronoun', '-'],\n",
       " ['.', 'SENT', '-'],\n",
       " ['ŒòŒµœÅŒ¨œÄœâŒΩ', 'adjective', '<unknown>'],\n",
       " ['·ºúœÄŒøœÄŒøœÉ', 'noun', '<unknown>'],\n",
       " ['Œø·º∂Œ¥Œ±', 'verb', '-'],\n",
       " ['Œº·Ω≤ŒΩ', 'adverb', '-'],\n",
       " ['œÉŒ±œÜ·ø∂œÉ', 'verb', '<unknown>'],\n",
       " ['·ΩÖœÑŒπ', 'conjunction', '-'],\n",
       " ['·ºÄœáŒ∏Œ≠œÉŒµœÑŒ±Œπ', 'verb', '-'],\n",
       " [',', 'SENT', '-'],\n",
       " ['œÉœÜ·ø∑ŒΩ', 'pronoun', '-'],\n",
       " ['Œ¥', 'unknown', '-'],\n",
       " ['‚Äô', 'unknown', '-'],\n",
       " ['Œ±·ΩêœÑ·Ω∏ŒΩ', 'pronoun', '-'],\n",
       " ['Œø·ΩïŒΩŒµŒ∫', 'verb', '<unknown>'],\n",
       " ['‚Äô', 'unknown', '-'],\n",
       " ['·ºêœÄŒµŒ≥ŒµœÅ·ø∂', 'verb', '-'],\n",
       " ['.', 'SENT', '-'],\n",
       " ['Œ†ŒπœÉŒ∏Œ≠œÑŒ±ŒπœÅŒøœÉ', 'adjective', '<unknown>'],\n",
       " ['Œ∫Œ±Œ∫·ø∂œÇ', 'adverb', '-'],\n",
       " ['œÉœç', 'pronoun', '-'],\n",
       " ['Œ≥', 'particle', '-'],\n",
       " ['‚Äô', 'unknown', '-'],\n",
       " ['·ºÄœÄœåŒªŒø·øê', 'verb', '<unknown>'],\n",
       " [',', 'SENT', '-'],\n",
       " ['·Ω•œÇ', 'conjunction', '-'],\n",
       " ['Œº', 'verb', '<unknown>'],\n",
       " ['‚Äô', 'SENT', '-'],\n",
       " ['·ºÄœÄŒ≠Œ∫œÑŒµŒπŒΩŒ±œÇ', 'verb', '-'],\n",
       " ['Œ¥Œ≠ŒµŒπ', 'noun', '-'],\n",
       " ['.', 'SENT', '-'],\n",
       " ['·ºòœÖŒµŒªœÄŒØŒ¥Œ∑œÉ', 'adjective', '<unknown>'],\n",
       " ['Œø·º¥ŒºŒøŒπ', 'interjection', '-'],\n",
       " ['Œ∫Œ±Œ∫ŒøŒ¥Œ±ŒØŒºœâŒΩ', 'adjective', '-'],\n",
       " ['œá·Ω†', 'article', '-'],\n",
       " ['Œ∫ŒøŒªŒøŒπœåœÇ', 'noun', '-'],\n",
       " ['ŒºŒø·º¥œáŒµœÑŒ±Œπ', 'verb', '-'],\n",
       " ['·ΩëœÄ·Ω∏', 'preposition', '-'],\n",
       " ['œÑŒø·ø¶', 'article', '-'],\n",
       " ['Œ¥Œ≠ŒøœÖœÇ\\\\', 'noun', '<unknown>'],\n",
       " ['.', 'SENT', '-'],\n",
       " ['Œ†ŒπœÉŒ∏Œ≠œÑŒ±ŒπœÅŒøœÉ', 'adjective', '<unknown>'],\n",
       " ['·Ω¶', 'interjection', '-'],\n",
       " ['Œ¥ŒµŒπŒªœåœÑŒ±œÑŒøŒΩ', 'adjective', '-'],\n",
       " ['œÉ·Ω∫', 'pronoun', '-'],\n",
       " ['Œ∏Œ∑œÅŒØŒøŒΩ', 'noun', '-'],\n",
       " [',', 'SENT', '-'],\n",
       " ['Œ¥ŒµŒØœÉŒ±œÇ', 'verb', '-'],\n",
       " ['·ºÄœÜ·øÜŒ∫Œ±œÇ', 'verb', '-'],\n",
       " ['œÑ·Ω∏ŒΩ', 'article', '-'],\n",
       " ['Œ∫ŒøŒªŒøŒπœåŒΩ', 'noun', '-'],\n",
       " [';', 'SENT', '-'],\n",
       " ['·ºòœÖŒµŒªœÄŒØŒ¥Œ∑œÉ', 'adjective', '<unknown>'],\n",
       " ['Œµ·º∞œÄŒ≠', 'verb', '-'],\n",
       " ['ŒºŒøŒπ', 'pronoun', '-'],\n",
       " [',', 'SENT', '-'],\n",
       " ['œÉ·Ω∫', 'pronoun', '-'],\n",
       " ['Œ¥·Ω≤', 'adverb', '-'],\n",
       " ['œÑ·Ω¥ŒΩ', 'article', '-'],\n",
       " ['Œ∫ŒøœÅœéŒΩŒ∑ŒΩ', 'noun', '-'],\n",
       " ['Œø·ΩêŒ∫', 'adverb', '-'],\n",
       " ['·ºÄœÜ·øÜŒ∫Œ±œÇ', 'verb', '-'],\n",
       " ['Œ∫Œ±œÑŒ±œÄŒµœÉœéŒΩ', 'verb', '-'],\n",
       " [';', 'SENT', '-'],\n",
       " ['Œ†ŒπœÉŒ∏Œ≠œÑŒ±ŒπœÅŒøœÉ', 'adjective', '<unknown>'],\n",
       " ['Œº·Ω∞', 'adverb', '-'],\n",
       " ['ŒîŒØ', 'proper', '-'],\n",
       " ['‚Äô', 'unknown', '-'],\n",
       " ['Œø·ΩêŒ∫', 'adverb', '-'],\n",
       " ['·ºîŒ≥œâŒ≥Œµ', 'pronoun', '-'],\n",
       " ['.', 'SENT', '-'],\n",
       " ['·ºòœÖŒµŒªœÄŒØŒ¥Œ∑œÉ', 'adjective', '<unknown>'],\n",
       " ['œÄŒø·ø¶', 'adverb', '-'],\n",
       " ['Œ≥Œ¨œÅ', 'adverb', '-'],\n",
       " ['·ºêœÉœÑ', 'verb', '<unknown>'],\n",
       " ['‚Äô', 'unknown', '-'],\n",
       " [';', 'SENT', '-'],\n",
       " ['Œ†ŒπœÉŒ∏Œ≠œÑŒ±ŒπœÅŒøœÉ', 'adjective', '<unknown>'],\n",
       " ['·ºÄœÄŒ≠œÄœÑŒµœÑŒø', 'verb', '-'],\n",
       " ['.', 'SENT', '-'],\n",
       " ['·ºòœÖŒµŒªœÄŒØŒ¥Œ∑œÉ', 'adjective', '<unknown>'],\n",
       " ['Œø·ΩêŒ∫', 'adverb', '-'],\n",
       " ['·ºÜœÅ', 'verb', '<unknown>'],\n",
       " ['‚Äô', 'unknown', '-'],\n",
       " ['·ºÄœÜ·øÜŒ∫Œ±œÇ', 'verb', '-'],\n",
       " [';', 'SENT', '-'],\n",
       " ['·Ω¶Œ≥Œ¨Œ∏', 'adjective', '<unknown>'],\n",
       " ['‚Äô', 'SENT', '-'],\n",
       " ['·Ω°œÇ', 'conjunction', '-'],\n",
       " ['·ºÄŒΩŒ¥œÅŒµ·øñŒøœÇ', 'adjective', '-'],\n",
       " ['Œµ·º∂', 'verb', '-'],\n",
       " ['.', 'SENT', '-'],\n",
       " ['·ºúœÄŒøœà', 'verb', '<unknown>'],\n",
       " ['·ºÑŒΩŒøŒπŒ≥Œµ', 'verb', '-'],\n",
       " ['œÑ·Ω¥ŒΩ', 'article', '-'],\n",
       " ['·ΩïŒªŒ∑ŒΩ', 'noun', '-'],\n",
       " [',', 'SENT', '-'],\n",
       " ['·ºµŒΩ', 'pronoun', '-'],\n",
       " ['‚Äô', 'SENT', '-'],\n",
       " ['·ºêŒæŒ≠ŒªŒ∏œâ', 'verb', '-'],\n",
       " ['œÄŒøœÑŒ≠', 'particle', '-'],\n",
       " ['.', 'SENT', '-'],\n",
       " ['·ºòœÖŒµŒªœÄŒØŒ¥Œ∑œÉ', 'adjective', '<unknown>'],\n",
       " ['·Ω¶', 'interjection', '-'],\n",
       " ['·º©œÅŒ¨Œ∫ŒªŒµŒπœÇ', 'noun', '-'],\n",
       " ['œÑŒøœÖœÑ·Ω∂', 'pronoun', '-'],\n",
       " ['œÑŒØ', 'pronoun', '-'],\n",
       " ['œÄŒøœÑ', 'verb', '<unknown>'],\n",
       " ['‚Äô', 'SENT', '-']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.tag(\" \".join(birds[1000:1100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "Present two examples: one suitable for automatic lemmatization and the other more as a support for the reader/annotator.\n",
    "\n",
    "Main difference: how words that may correspond to multiple lemmata are handled.\n",
    "\n",
    "### Latin\n",
    "\n",
    "#### CLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.utils.file_operations import open_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training sentences\n",
    "rel_path = os.path.join('~/cltk_data/latin/model/latin_models_cltk/lemmata/backoff')\n",
    "path = os.path.expanduser(rel_path)\n",
    "\n",
    "# Check for presence of latin_pos_lemmatized_sents\n",
    "file = 'latin_pos_lemmatized_sents.pickle' \n",
    "latin_pos_lemmatized_sents_path = os.path.join(path, file)\n",
    "if os.path.isfile(latin_pos_lemmatized_sents_path):\n",
    "    latin_pos_lemmatized_sents = open_pickle(latin_pos_lemmatized_sents_path)\n",
    "else:\n",
    "    latin_pos_lemmatized_sents = []\n",
    "    print('The file %s is not available in cltk_data' % file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cum', 'cum2', 'c'),\n",
       "  ('esset', 'sum', 'v'),\n",
       "  ('caesar', 'caesar', 'n'),\n",
       "  ('in', 'in', 'r'),\n",
       "  ('citeriore', 'citer', 'a'),\n",
       "  ('gallia', 'gallia', 'n'),\n",
       "  ('in', 'in', 'r'),\n",
       "  ('hibernis', 'hibernus', 'a'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('ita', 'ita', 'd'),\n",
       "  ('uti', 'ut', 'c'),\n",
       "  ('supra', 'supra', 'd'),\n",
       "  ('demonstrauimus', 'demonstro', 'v'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('crebri', 'creber', 'a'),\n",
       "  ('ad', 'ad', 'r'),\n",
       "  ('eum', 'is', 'p'),\n",
       "  ('rumores', 'rumor', 'n'),\n",
       "  ('adferebantur', 'affero', 'v'),\n",
       "  ('litteris', 'littera', 'n'),\n",
       "  ('-que', '-que', 'c'),\n",
       "  ('item', 'item', 'd'),\n",
       "  ('labieni', 'labienus', 'n'),\n",
       "  ('certior', 'certus', 'a'),\n",
       "  ('fiebat', 'fio', 'v'),\n",
       "  ('omnes', 'omnis', 'a'),\n",
       "  ('belgas', 'belgae', 'n'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('quam', 'qui', 'p'),\n",
       "  ('tertiam', 'tertius', 'm'),\n",
       "  ('esse', 'sum', 'v'),\n",
       "  ('galliae', 'gallia', 'n'),\n",
       "  ('partem', 'pars', 'n'),\n",
       "  ('dixeramus', 'dico', 'v'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('contra', 'contra', 'r'),\n",
       "  ('populum', 'populus', 'n'),\n",
       "  ('romanum', 'romanus', 'a'),\n",
       "  ('coniurare', 'coniuro', 'v'),\n",
       "  ('obsides', 'obses', 'n'),\n",
       "  ('-que', '-que', 'c'),\n",
       "  ('inter', 'inter', 'r'),\n",
       "  ('se', 'sui', 'p'),\n",
       "  ('dare', 'do', 'v'),\n",
       "  ('.', 'punc', 'u')],\n",
       " [('coniurandi', 'coniuro', 'v'),\n",
       "  ('has', 'hic', 'p'),\n",
       "  ('esse', 'sum', 'v'),\n",
       "  ('causas', 'causa', 'n'),\n",
       "  ('primum', 'primus', 'd'),\n",
       "  ('quod', 'quod', 'c'),\n",
       "  ('uererentur', 'uereor', 'v'),\n",
       "  ('ne', 'ne', 'c'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('omni', 'omnis', 'a'),\n",
       "  ('pacata', 'paco', 'v'),\n",
       "  ('gallia', 'gallia', 'n'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('ad', 'ad', 'r'),\n",
       "  ('eos', 'is', 'p'),\n",
       "  ('exercitus', 'exercitus', 'n'),\n",
       "  ('noster', 'noster', 'p'),\n",
       "  ('adduceretur', 'adduco', 'v'),\n",
       "  (';', 'punc', 'u')],\n",
       " [('deinde', 'deinde', 'd'),\n",
       "  ('quod', 'quod', 'c'),\n",
       "  ('ab', 'ab', 'r'),\n",
       "  ('non', 'non', 'd'),\n",
       "  ('nullis', 'nullus', 'a'),\n",
       "  ('gallis', 'galli', 'n'),\n",
       "  ('sollicitarentur', 'sollicito', 'v'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('partim', 'pars', 'd'),\n",
       "  ('qui', 'qui', 'p'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('ut', 'ut', 'c'),\n",
       "  ('germanos', 'germani', 'n'),\n",
       "  ('diutius', 'diu', 'd'),\n",
       "  ('in', 'in', 'r'),\n",
       "  ('gallia', 'gallia', 'n'),\n",
       "  ('uersari', 'uerso', 'v'),\n",
       "  ('noluerant', 'nolo', 'v'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('ita', 'ita', 'd'),\n",
       "  ('populi', 'populus', 'n'),\n",
       "  ('romani', 'romanus', 'a'),\n",
       "  ('exercitum', 'exercitus', 'n'),\n",
       "  ('hiemare', 'hiemo', 'v'),\n",
       "  ('atque', 'atque', 'c'),\n",
       "  ('inueterascere', 'inueterasco', 'v'),\n",
       "  ('in', 'in', 'r'),\n",
       "  ('gallia', 'gallia', 'n'),\n",
       "  ('moleste', 'molestus', 'd'),\n",
       "  ('ferebant', 'fero', 'v'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('partim', 'pars', 'd'),\n",
       "  ('qui', 'qui', 'p'),\n",
       "  ('mobilitate', 'mobilitas', 'n'),\n",
       "  ('et', 'et', 'c'),\n",
       "  ('leuitate', 'leuitas', 'n'),\n",
       "  ('animi', 'animus', 'n'),\n",
       "  ('nouis', 'nouus', 'a'),\n",
       "  ('imperiis', 'imperium', 'n'),\n",
       "  ('studebant', 'studeo', 'v'),\n",
       "  (';', 'punc', 'u')],\n",
       " [('ab', 'ab', 'r'),\n",
       "  ('non', 'non', 'd'),\n",
       "  ('nullis', 'nullus', 'a'),\n",
       "  ('etiam', 'etiam', 'd'),\n",
       "  ('quod', 'quod', 'c'),\n",
       "  ('in', 'in', 'r'),\n",
       "  ('gallia', 'gallia', 'n'),\n",
       "  ('a', 'ab', 'r'),\n",
       "  ('potentioribus', 'possum', 'v'),\n",
       "  ('atque', 'atque', 'c'),\n",
       "  ('iis', 'is', 'p'),\n",
       "  ('qui', 'qui', 'p'),\n",
       "  ('ad', 'ad', 'r'),\n",
       "  ('conducendos', 'conduco', 'v'),\n",
       "  ('homines', 'homo', 'n'),\n",
       "  ('facultates', 'facultas', 'n'),\n",
       "  ('habebant', 'habeo', 'v'),\n",
       "  ('uulgo', 'uulgus', 'd'),\n",
       "  ('regna', 'regnum', 'n'),\n",
       "  ('occupabantur', 'occupo', 'v'),\n",
       "  (';', 'punc', 'u'),\n",
       "  ('sollicitarentur', 'sollicito', 'v')],\n",
       " [('qui', 'qui', 'p'),\n",
       "  ('minus', 'paruus', 'd'),\n",
       "  ('facile', 'facilis', 'd'),\n",
       "  ('eam', 'is', 'p'),\n",
       "  ('rem', 'res', 'n'),\n",
       "  ('imperio', 'imperium', 'n'),\n",
       "  ('nostro', 'noster', 'p'),\n",
       "  ('consequi', 'consequor', 'v'),\n",
       "  ('poterant', 'possum', 'v'),\n",
       "  ('.', 'punc', 'u')],\n",
       " [('his', 'hic', 'p'),\n",
       "  ('nuntiis', 'nuntius', 'a'),\n",
       "  ('litteris', 'littera', 'n'),\n",
       "  ('-que', '-que', 'c'),\n",
       "  ('commotus', 'commoueo', 'v'),\n",
       "  ('caesar', 'caesar', 'n'),\n",
       "  ('duas', 'duo', 'm'),\n",
       "  ('legiones', 'legio', 'n'),\n",
       "  ('in', 'in', 'r'),\n",
       "  ('citeriore', 'citer', 'a'),\n",
       "  ('gallia', 'gallia', 'n'),\n",
       "  ('nouas', 'nouus', 'a'),\n",
       "  ('conscripsit', 'conscribo', 'v'),\n",
       "  ('et', 'et', 'c'),\n",
       "  ('inita', 'ineo', 'v'),\n",
       "  ('aestate', 'aestas', 'n'),\n",
       "  ('in', 'in', 'r'),\n",
       "  ('ulteriorem', 'ulter', 'a'),\n",
       "  ('galliam', 'gallia', 'n'),\n",
       "  ('qui', 'qui', 'p'),\n",
       "  ('deduceret', 'deduco', 'v'),\n",
       "  ('q', 'quintus', 'n'),\n",
       "  ('pedium', 'pedius', 'n'),\n",
       "  ('legatum', 'legatus', 'n'),\n",
       "  ('misit', 'mitto', 'v'),\n",
       "  ('.', 'punc', 'u')],\n",
       " [('ipse', 'ipse', 'p'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('cum', 'cum2', 'c'),\n",
       "  ('primum', 'primus', 'd'),\n",
       "  ('pabuli', 'pabulum', 'n'),\n",
       "  ('copia', 'copia', 'n'),\n",
       "  ('esse', 'sum', 'v'),\n",
       "  ('inciperet', 'incipio', 'v'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('ad', 'ad', 'r'),\n",
       "  ('exercitum', 'exercitus', 'n'),\n",
       "  ('uenit', 'uenio', 'v'),\n",
       "  ('.', 'punc', 'u')],\n",
       " [('dat', 'do', 'v'),\n",
       "  ('negotium', 'negotium', 'n'),\n",
       "  ('senonibus', 'senones', 'n'),\n",
       "  ('reliquis', 'reliquus', 'a'),\n",
       "  ('-que', '-que', 'c'),\n",
       "  ('gallis', 'galli', 'n'),\n",
       "  ('qui', 'qui', 'p'),\n",
       "  ('finitimi', 'finitimus', 'a'),\n",
       "  ('belgis', 'belgae', 'n'),\n",
       "  ('erant', 'sum', 'v'),\n",
       "  ('uti', 'ut', 'c'),\n",
       "  ('ea', 'is', 'p'),\n",
       "  ('quae', 'qui', 'p'),\n",
       "  ('apud', 'apud', 'r'),\n",
       "  ('eos', 'is', 'p'),\n",
       "  ('gerantur', 'gero', 'v'),\n",
       "  ('cognoscant', 'cognosco', 'v'),\n",
       "  ('se', 'sui', 'p'),\n",
       "  ('-que', '-que', 'c'),\n",
       "  ('de', 'de', 'r'),\n",
       "  ('his', 'hic', 'p'),\n",
       "  ('rebus', 'res', 'n'),\n",
       "  ('certiorem', 'certus', 'a'),\n",
       "  ('faciant', 'facio', 'v'),\n",
       "  ('.', 'punc', 'u')],\n",
       " [('hi', 'hic', 'p'),\n",
       "  ('constanter', 'consto', 'd'),\n",
       "  ('omnes', 'omnis', 'a'),\n",
       "  ('nuntiauerunt', 'nuntio', 'v'),\n",
       "  ('manus', 'manus', 'n'),\n",
       "  ('cogi', 'cogo', 'v'),\n",
       "  (',', 'punc', 'u'),\n",
       "  ('exercitum', 'exercitus', 'n'),\n",
       "  ('in', 'in', 'r'),\n",
       "  ('unum', 'unus', 'm'),\n",
       "  ('locum', 'locus', 'n'),\n",
       "  ('conduci', 'conduco', 'v'),\n",
       "  ('.', 'punc', 'u')],\n",
       " [('tum', 'tum', 'd'),\n",
       "  ('uero', 'uerus', 'd'),\n",
       "  ('dubitandum', 'dubito', 'v'),\n",
       "  ('non', 'non', 'd'),\n",
       "  ('existimauit', 'existimo', 'v'),\n",
       "  ('quin', 'quin', 'c'),\n",
       "  ('ad', 'ad', 'r'),\n",
       "  ('eos', 'is', 'p'),\n",
       "  ('proficisceretur', 'proficiscor', 'v'),\n",
       "  ('.', 'punc', 'u'),\n",
       "  ('esse', 'sum', 'v')]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_pos_lemmatized_sents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "amicitia_sents = latinlibrary.sents('cicero/amic.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " '4',\n",
       " ']',\n",
       " 'Cum',\n",
       " 'enim',\n",
       " 'saepe',\n",
       " 'cum',\n",
       " 'me',\n",
       " 'ageres',\n",
       " 'ut',\n",
       " 'de',\n",
       " 'amicitia',\n",
       " 'scriberem',\n",
       " 'aliquid',\n",
       " ',',\n",
       " 'digna',\n",
       " 'mihi',\n",
       " 'res',\n",
       " 'cum',\n",
       " 'omnium',\n",
       " 'cognitione',\n",
       " 'tum',\n",
       " 'nostra',\n",
       " 'familiaritate',\n",
       " 'visa',\n",
       " 'est',\n",
       " '.']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amicitia_sents[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.lemmatize.latin.backoff import BackoffLatinLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "backoff_lemmatizer = BackoffLatinLemmatizer(train=latin_pos_lemmatized_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[', 'punc'),\n",
       " ('4', '4'),\n",
       " (']', 'punc'),\n",
       " ('Cum', 'Cos2'),\n",
       " ('enim', 'enim'),\n",
       " ('saepe', 'saepe'),\n",
       " ('cum', 'cum2'),\n",
       " ('me', 'ego'),\n",
       " ('ageres', 'ago'),\n",
       " ('ut', 'ut'),\n",
       " ('de', 'de'),\n",
       " ('amicitia', 'amicitia'),\n",
       " ('scriberem', 'scribo'),\n",
       " ('aliquid', 'aliquis'),\n",
       " (',', 'punc'),\n",
       " ('digna', 'dignus'),\n",
       " ('mihi', 'ego'),\n",
       " ('res', 'res'),\n",
       " ('cum', 'cum2'),\n",
       " ('omnium', 'omnis'),\n",
       " ('cognitione', 'cognitio'),\n",
       " ('tum', 'tum'),\n",
       " ('nostra', 'noster'),\n",
       " ('familiaritate', 'familiaritas'),\n",
       " ('visa', 'video'),\n",
       " ('est', 'sum'),\n",
       " ('.', 'punc')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backoff_lemmatizer.lemmatize(amicitia_sents[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But behind the scenes, this is what is going on:\n",
    "\n",
    "```python\n",
    "\n",
    "    def _define_lemmatizer(self):\n",
    "        # Suggested backoff chain--should be tested for optimal order\n",
    "        backoff0 = None\n",
    "        backoff1 = IdentityLemmatizer()\n",
    "        backoff2 = TrainLemmatizer(model=self.LATIN_OLD_MODEL, backoff=backoff1)\n",
    "        backoff3 = PPLemmatizer(regexps=self.latin_verb_patterns, pps=self.latin_pps, backoff=backoff2)                 \n",
    "        backoff4 = RegexpLemmatizer(self.latin_sub_patterns, backoff=backoff3)\n",
    "        backoff5 = UnigramLemmatizer(self.train_sents, backoff=backoff4)\n",
    "        backoff6 = TrainLemmatizer(model=self.LATIN_MODEL, backoff=backoff5)      \n",
    "        #backoff7 = BigramPOSLemmatizer(self.pos_train_sents, include=['cum'], backoff=backoff6)\n",
    "        #lemmatizer = backoff7\n",
    "        lemmatizer = backoff6\n",
    "        return lemmatizer\n",
    "\n",
    "```\n",
    "\n",
    "further readings: \n",
    "* https://github.com/cltk/cltk/blob/master/cltk/lemmatize/latin/backoff.py\n",
    "* https://disiectamembra.wordpress.com/2016/08/23/wrapping-up-google-summer-of-code/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyCollatinus\n",
    "\n",
    "* Python port of the [Collatinus lemmatizer](https://github.com/biblissima/collatinus)\n",
    "* good if you can read some French (or at least practice it) üòâ\n",
    "* the PoS tags used by Collatinus are explained [here](https://github.com/biblissima/collatinus/blob/master/NOTES_Tagger.md)\n",
    "* morphological analysis not readily machine readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import and instantiate the PyCollatinus lemmatizer (`Lemmatiseur`) ‚Äì and ignore the long list of warnings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: honor has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: aer has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: tethys has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: opes has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: dos has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: corpus has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: ciuis has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: thales has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: poesis has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: manes has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: turris has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: uis has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: nauis has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: apis has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: mare has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: moenia has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: animal has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: mille has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/rromanello/.local/share/virtualenvs/sunoikisis_dc-Xcx-IOWS/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: ille has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n"
     ]
    }
   ],
   "source": [
    "from pycollatinus import Lemmatiseur\n",
    "analyzer = Lemmatiseur()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pycollatinus.lemmatiseur.Lemmatiseur at 0x10f2250f0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lemmatiser can take as input a **single word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'desinence': 'ito',\n",
       "  'form': 'cogito',\n",
       "  'lemma': 'cogo',\n",
       "  'morph': '2√®me singulier imp√©ratif futur actif',\n",
       "  'radical': 'cog'},\n",
       " {'desinence': 'ito',\n",
       "  'form': 'cogito',\n",
       "  'lemma': 'cogo',\n",
       "  'morph': '3√®me singulier imp√©ratif futur actif',\n",
       "  'radical': 'cog'},\n",
       " {'desinence': 'o',\n",
       "  'form': 'cogito',\n",
       "  'lemma': 'cogito',\n",
       "  'morph': '1√®re singulier indicatif pr√©sent actif',\n",
       "  'radical': 'cogit'},\n",
       " {'desinence': 'o',\n",
       "  'form': 'cogito',\n",
       "  'lemma': 'cogito',\n",
       "  'morph': '1√®re singulier indicatif pr√©sent actif',\n",
       "  'radical': 'cogit'}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(analyzer.lemmatise(\"Cogito\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or an **entire sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'desinence': 'ito',\n",
       "   'form': 'cogito',\n",
       "   'lemma': 'cogo',\n",
       "   'morph': '2√®me singulier imp√©ratif futur actif',\n",
       "   'radical': 'cog'},\n",
       "  {'desinence': 'ito',\n",
       "   'form': 'cogito',\n",
       "   'lemma': 'cogo',\n",
       "   'morph': '3√®me singulier imp√©ratif futur actif',\n",
       "   'radical': 'cog'},\n",
       "  {'desinence': 'o',\n",
       "   'form': 'cogito',\n",
       "   'lemma': 'cogito',\n",
       "   'morph': '1√®re singulier indicatif pr√©sent actif',\n",
       "   'radical': 'cogit'},\n",
       "  {'desinence': 'o',\n",
       "   'form': 'cogito',\n",
       "   'lemma': 'cogito',\n",
       "   'morph': '1√®re singulier indicatif pr√©sent actif',\n",
       "   'radical': 'cogit'}],\n",
       " [{'desinence': 'o',\n",
       "   'form': 'ergo',\n",
       "   'lemma': 'ergo',\n",
       "   'morph': '1√®re singulier indicatif pr√©sent actif',\n",
       "   'radical': 'erg'},\n",
       "  {'desinence': '',\n",
       "   'form': 'ergo',\n",
       "   'lemma': 'ergo',\n",
       "   'morph': '-',\n",
       "   'radical': 'ergo'},\n",
       "  {'desinence': '',\n",
       "   'form': 'ergo',\n",
       "   'lemma': 'ergo',\n",
       "   'morph': 'positif',\n",
       "   'radical': 'ergo'}],\n",
       " [{'desinence': 'um',\n",
       "   'form': 'sum',\n",
       "   'lemma': 'sum',\n",
       "   'morph': '1√®re singulier indicatif pr√©sent actif',\n",
       "   'radical': 's'}]]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(analyzer.lemmatise_multiple(\"Cogito ergo sum\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to output the lemmatisation in a more intellegible way..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\tcogito\t\tcogo 2√®me singulier imp√©ratif futur actif\n",
      "1.2\tcogito\t\tcogo 3√®me singulier imp√©ratif futur actif\n",
      "1.3\tcogito\t\tcogito 1√®re singulier indicatif pr√©sent actif\n",
      "1.4\tcogito\t\tcogito 1√®re singulier indicatif pr√©sent actif\n",
      "2.1\tergo\t\tergo 1√®re singulier indicatif pr√©sent actif\n",
      "2.2\tergo\t\tergo -\n",
      "2.3\tergo\t\tergo positif\n",
      "3.1\tsum\t\tsum 1√®re singulier indicatif pr√©sent actif\n"
     ]
    }
   ],
   "source": [
    "# the analyzer output is essentially a list of lists\n",
    "# for each analyzed token it returns a list of possible lemmata\n",
    "# here we iterate through both lists and display the analysis as we go along\n",
    "\n",
    "for n, result in enumerate(analyzer.lemmatise_multiple(\"Cogito ergo sum\")):\n",
    "    for i, lemma in enumerate(result):\n",
    "        print(\n",
    "            \"{}.{}\\t{}\\t\\t{} {}\".format(\n",
    "                n + 1,\n",
    "                i + 1,\n",
    "                lemma[\"form\"],\n",
    "                lemma[\"lemma\"],\n",
    "                lemma[\"morph\"]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the same but also with PoS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\tcogito\tv\tcogo 2√®me singulier imp√©ratif futur actif\n",
      "1.2\tcogito\tv\tcogo 3√®me singulier imp√©ratif futur actif\n",
      "1.3\tcogito\tv\tcogito 1√®re singulier indicatif pr√©sent actif\n",
      "1.4\tcogito\tv\tcogito 1√®re singulier indicatif pr√©sent actif\n",
      "2.1\tergo\tv\tergo 1√®re singulier indicatif pr√©sent actif\n",
      "2.2\tergo\tc\tergo -\n",
      "2.3\tergo\td\tergo positif\n",
      "3.1\tsum\tv\tsum 1√®re singulier indicatif pr√©sent actif\n"
     ]
    }
   ],
   "source": [
    "# the analyzer output is essentially a list of lists\n",
    "# for each analyzed token it returns a list of possible lemmata\n",
    "# here we iterate through both lists and display the analysis as we go along\n",
    "\n",
    "for n, result in enumerate(analyzer.lemmatise_multiple(\"Cogito ergo sum\", pos=True),):\n",
    "    for i, lemma in enumerate(result):\n",
    "        print(\n",
    "            \"{}.{}\\t{}\\t{}\\t{} {}\".format(\n",
    "                n + 1,\n",
    "                i + 1,\n",
    "                lemma[\"form\"],\n",
    "                lemma[\"pos\"],\n",
    "                lemma[\"lemma\"],\n",
    "                lemma[\"morph\"]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "- install Jupyter and all necessary libraries using the instructions on the Wiki\n",
    "- prepare a corpus of Ancient Greek (by re-running code above)\n",
    "    - use Perseus data\n",
    "    - convert the data (TEI/XML + Betacode => Plain Text + UTF-8)\n",
    "    - create a `PlaintextCorpusReader`\n",
    "- pick a specific work in the corpus (e.g. one you are particularly familiar with)\n",
    "- lemmatize using CLTK (see documentation for [Greek lemmatization](http://docs.cltk.org/en/latest/greek.html#lemmatization))\n",
    "- and then... spot the errors! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "621px",
    "left": "0px",
    "right": "1169px",
    "top": "111px",
    "width": "234px"
   },
   "toc_section_display": true,
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
