{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech tagging and lemmatisation with 🐍\n",
    "\n",
    "See information on the [Sunoikisis Wiki](https://github.com/SunoikisisDC/SunoikisisDC-2017-2018/wiki/Python-2:-Part-of-Speech-tagging-and-lemmatisation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.83'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cltk.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.corpus.utils.importer import CorpusImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "grk_corpus_importer = CorpusImporter('greek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greek_software_tlgu',\n",
       " 'greek_text_perseus',\n",
       " 'phi7',\n",
       " 'tlg',\n",
       " 'greek_proper_names_cltk',\n",
       " 'greek_models_cltk',\n",
       " 'greek_treebank_perseus',\n",
       " 'greek_lexica_perseus',\n",
       " 'greek_training_set_sentence_cltk',\n",
       " 'greek_word2vec_cltk',\n",
       " 'greek_text_lacus_curtius',\n",
       " 'greek_text_first1kgreek']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grk_corpus_importer.list_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 100% 143.79 MiB | 4.02 MiB/s s \r"
     ]
    }
   ],
   "source": [
    "grk_corpus_importer.import_corpus('greek_text_perseus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: `cltk.corpus.latin.latinlibrary` is a shortcut for several things, and there is nothing comparable (yet) for Greek (see [source code](https://github.com/cltk/cltk/blob/master/cltk/corpus/latin/__init__.py))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_corpus_importer = CorpusImporter('latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 100% 35.50 MiB | 5.91 MiB/s \r"
     ]
    }
   ],
   "source": [
    "la_corpus_importer.import_corpus('latin_text_latin_library')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.corpus.latin import latinlibrary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: Disclaimer about what the library does behind the scenes when one imports the submodule `latinlibrary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "amicitia_words = latinlibrary.words('cicero/amic.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11618"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amicitia_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get `n` number of tokens from this text by using the *slice notation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cicero',\n",
       " ':',\n",
       " 'de',\n",
       " 'Amicitia',\n",
       " 'M.',\n",
       " 'TVLLI',\n",
       " 'CICERONIS',\n",
       " 'LAELIVS',\n",
       " 'DE',\n",
       " 'AMICITIA']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first ten tokens\n",
    "amicitia_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or the last token\n",
    "amicitia_words[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also count occurrences by using the `count()` method and passing as parameter the token we want to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amicitia_words.count('et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amicitia_words.count('amicitia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look to the `type` of the variable `amicitia_words` where we loaded the content of Cicero's *De Amicitia*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.util.StreamBackedCorpusView"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(amicitia_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on StreamBackedCorpusView in module nltk.corpus.reader.util object:\n",
      "\n",
      "class StreamBackedCorpusView(nltk.collections.AbstractLazySequence)\n",
      " |  A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      " |  it can be accessed by index, iterated over, etc.  However, the\n",
      " |  tokens are only constructed as-needed -- the entire corpus is\n",
      " |  never stored in memory at once.\n",
      " |  \n",
      " |  The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      " |  a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      " |  and a block reader.  A \"block reader\" is a function that reads\n",
      " |  zero or more tokens from a stream, and returns them as a list.  A\n",
      " |  very simple example of a block reader is:\n",
      " |  \n",
      " |      >>> def simple_block_reader(stream):\n",
      " |      ...     return stream.readline().split()\n",
      " |  \n",
      " |  This simple block reader reads a single line at a time, and\n",
      " |  returns a single token (consisting of a string) for each\n",
      " |  whitespace-separated substring on the line.\n",
      " |  \n",
      " |  When deciding how to define the block reader for a given\n",
      " |  corpus, careful consideration should be given to the size of\n",
      " |  blocks handled by the block reader.  Smaller block sizes will\n",
      " |  increase the memory requirements of the corpus view's internal\n",
      " |  data structures (by 2 integers per block).  On the other hand,\n",
      " |  larger block sizes may decrease performance for random access to\n",
      " |  the corpus.  (But note that larger block sizes will *not*\n",
      " |  decrease performance for iteration.)\n",
      " |  \n",
      " |  Internally, ``CorpusView`` maintains a partial mapping from token\n",
      " |  index to file position, with one entry per block.  When a token\n",
      " |  with a given index *i* is requested, the ``CorpusView`` constructs\n",
      " |  it as follows:\n",
      " |  \n",
      " |    1. First, it searches the toknum/filepos mapping for the token\n",
      " |       index closest to (but less than or equal to) *i*.\n",
      " |  \n",
      " |    2. Then, starting at the file position corresponding to that\n",
      " |       index, it reads one block at a time using the block reader\n",
      " |       until it reaches the requested token.\n",
      " |  \n",
      " |  The toknum/filepos mapping is created lazily: it is initially\n",
      " |  empty, but every time a new block is read, the block's\n",
      " |  initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      " |  map has one entry per block.)\n",
      " |  \n",
      " |  In order to increase efficiency for random access patterns that\n",
      " |  have high degrees of locality, the corpus view may cache one or\n",
      " |  more blocks.\n",
      " |  \n",
      " |  :note: Each ``CorpusView`` object internally maintains an open file\n",
      " |      object for its underlying corpus file.  This file should be\n",
      " |      automatically closed when the ``CorpusView`` is garbage collected,\n",
      " |      but if you wish to close it manually, use the ``close()``\n",
      " |      method.  If you access a ``CorpusView``'s items after it has been\n",
      " |      closed, the file object will be automatically re-opened.\n",
      " |  \n",
      " |  :warning: If the contents of the file are modified during the\n",
      " |      lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      " |      is undefined.\n",
      " |  \n",
      " |  :warning: If a unicode encoding is specified when constructing a\n",
      " |      ``CorpusView``, then the block reader may only call\n",
      " |      ``stream.seek()`` with offsets that have been returned by\n",
      " |      ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      " |      relative offsets, or with offsets based on string lengths, may\n",
      " |      lead to incorrect behavior.\n",
      " |  \n",
      " |  :ivar _block_reader: The function used to read\n",
      " |      a single block from the underlying file stream.\n",
      " |  :ivar _toknum: A list containing the token index of each block\n",
      " |      that has been processed.  In particular, ``_toknum[i]`` is the\n",
      " |      token index of the first token in block ``i``.  Together\n",
      " |      with ``_filepos``, this forms a partial mapping between token\n",
      " |      indices and file positions.\n",
      " |  :ivar _filepos: A list containing the file position of each block\n",
      " |      that has been processed.  In particular, ``_toknum[i]`` is the\n",
      " |      file position of the first character in block ``i``.  Together\n",
      " |      with ``_toknum``, this forms a partial mapping between token\n",
      " |      indices and file positions.\n",
      " |  :ivar _stream: The stream used to access the underlying corpus file.\n",
      " |  :ivar _len: The total number of tokens in the corpus, if known;\n",
      " |      or None, if the number of tokens is not yet known.\n",
      " |  :ivar _eofpos: The character position of the last character in the\n",
      " |      file.  This is calculated when the corpus view is initialized,\n",
      " |      and is used to decide when the end of file has been reached.\n",
      " |  :ivar _cache: A cache of the most recently read block.  It\n",
      " |     is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      " |     start_toknum is the token index of the first token in the block;\n",
      " |     end_toknum is the token index of the first token not in the\n",
      " |     block; and tokens is a list of the tokens in the block.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StreamBackedCorpusView\n",
      " |      nltk.collections.AbstractLazySequence\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |      Return a list concatenating self with other.\n",
      " |  \n",
      " |  __getitem__(self, i)\n",
      " |      Return the *i* th token in the corpus file underlying this\n",
      " |      corpus view.  Negative indices and spans are both supported.\n",
      " |  \n",
      " |  __init__(self, fileid, block_reader=None, startpos=0, encoding='utf8')\n",
      " |      Create a new corpus view, based on the file ``fileid``, and\n",
      " |      read with ``block_reader``.  See the class documentation\n",
      " |      for more information.\n",
      " |      \n",
      " |      :param fileid: The path to the file that is read by this\n",
      " |          corpus view.  ``fileid`` can either be a string or a\n",
      " |          ``PathPointer``.\n",
      " |      \n",
      " |      :param startpos: The file position at which the view will\n",
      " |          start reading.  This can be used to skip over preface\n",
      " |          sections.\n",
      " |      \n",
      " |      :param encoding: The unicode encoding that should be used to\n",
      " |          read the file's contents.  If no encoding is specified,\n",
      " |          then the file's contents will be read as a non-unicode\n",
      " |          string (i.e., a str).\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of tokens in the corpus file underlying this\n",
      " |      corpus view.\n",
      " |  \n",
      " |  __mul__(self, count)\n",
      " |      Return a list concatenating self with itself ``count`` times.\n",
      " |  \n",
      " |  __radd__(self, other)\n",
      " |      Return a list concatenating other with self.\n",
      " |  \n",
      " |  __rmul__(self, count)\n",
      " |      Return a list concatenating self with itself ``count`` times.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Close the file stream associated with this corpus view.  This\n",
      " |      can be useful if you are worried about running out of file\n",
      " |      handles (although the stream should automatically be closed\n",
      " |      upon garbage collection of the corpus view).  If the corpus\n",
      " |      view is accessed after it is closed, it will be automatically\n",
      " |      re-opened.\n",
      " |  \n",
      " |  iterate_from(self, start_tok)\n",
      " |      Return an iterator that generates the tokens in the corpus\n",
      " |      file underlying this corpus view, starting at the token number\n",
      " |      ``start``.  If ``start>=len(self)``, then this iterator will\n",
      " |      generate no tokens.\n",
      " |  \n",
      " |  read_block(self, stream)\n",
      " |      Read a block from the input stream.\n",
      " |      \n",
      " |      :return: a block of tokens from the input stream\n",
      " |      :rtype: list(any)\n",
      " |      :param stream: an input stream\n",
      " |      :type stream: stream\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  fileid\n",
      " |      The fileid of the file that is accessed by this view.\n",
      " |      \n",
      " |      :type: str or PathPointer\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.collections.AbstractLazySequence:\n",
      " |  \n",
      " |  __contains__(self, value)\n",
      " |      Return true if this list contains ``value``.\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, other, NotImplemented=NotImplemented)\n",
      " |      Return a >= b.  Computed by @total_ordering from (not a < b).\n",
      " |  \n",
      " |  __gt__(self, other, NotImplemented=NotImplemented)\n",
      " |      Return a > b.  Computed by @total_ordering from (not a < b) and (a != b).\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      :raise ValueError: Corpus view objects are unhashable.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return an iterator that generates the tokens in the corpus\n",
      " |      file underlying this corpus view.\n",
      " |  \n",
      " |  __le__(self, other, NotImplemented=NotImplemented)\n",
      " |      Return a <= b.  Computed by @total_ordering from (a < b) or (a == b).\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for this corpus view that is\n",
      " |      similar to a list's representation; but if it would be more\n",
      " |      than 60 characters long, it is truncated.\n",
      " |  \n",
      " |  __unicode__ = __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  count(self, value)\n",
      " |      Return the number of times this list contains ``value``.\n",
      " |  \n",
      " |  index(self, value, start=None, stop=None)\n",
      " |      Return the index of the first occurrence of ``value`` in this\n",
      " |      list that is greater than or equal to ``start`` and less than\n",
      " |      ``stop``.  Negative start and stop values are treated like negative\n",
      " |      slice bounds -- i.e., they count from the end of the list.\n",
      " |  \n",
      " |  unicode_repr = __repr__(self)\n",
      " |      Return a string representation for this corpus view that is\n",
      " |      similar to a list's representation; but if it would be more\n",
      " |      than 60 characters long, it is truncated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.collections.AbstractLazySequence:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(amicitia_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latin\n",
    "\n",
    "#### CLTK taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "CLTK linguistics models not available for unigram.pickle.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-002e391a20e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPOSTag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOSTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'latin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_ngram_123_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Gallia est omnis divisa in partes tres'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/cltk/tag/pos.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, language)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;34m\"\"\"Setup variables.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable_taggers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_language_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_language_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=no-self-use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/cltk/tag/pos.py\u001b[0m in \u001b[0;36m_setup_language_variables\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mtagger_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagger_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0;34m'CLTK linguistics models not available for {0}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagger_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mtagger_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtagger_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagger_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtagger_paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: CLTK linguistics models not available for unigram.pickle."
     ]
    }
   ],
   "source": [
    "from cltk.tag.pos import POSTag\n",
    "tagger = POSTag('latin')\n",
    "tagger.tag_ngram_123_backoff('Gallia est omnis divisa in partes tres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latin_text_perseus',\n",
       " 'latin_treebank_perseus',\n",
       " 'latin_text_latin_library',\n",
       " 'phi5',\n",
       " 'phi7',\n",
       " 'latin_proper_names_cltk',\n",
       " 'latin_models_cltk',\n",
       " 'latin_pos_lemmata_cltk',\n",
       " 'latin_treebank_index_thomisticus',\n",
       " 'latin_lexica_perseus',\n",
       " 'latin_training_set_sentence_cltk',\n",
       " 'latin_word2vec_cltk',\n",
       " 'latin_text_antique_digiliblt',\n",
       " 'latin_text_corpus_grammaticorum_latinorum',\n",
       " 'latin_text_poeti_ditalia']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_corpus_importer.list_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_corpus_importer.import_corpus('latin_models_cltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = POSTag('latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cltk.tag.pos.POSTag at 0x113476d68>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('91', 'Unk'), ('91', None), ('91', 'A-P---FN-')),\n",
       " (('92', 'Unk'), ('92', None), ('92', 'N-P---FN-')),\n",
       " (('93', 'Unk'), ('93', None), ('93', 'A-P---FN-')),\n",
       " (('94', 'Unk'), ('94', None), ('94', 'N-P---FN-')),\n",
       " (('95', 'Unk'), ('95', None), ('95', 'A-P---FN-')),\n",
       " (('96', 'Unk'), ('96', None), ('96', 'N-P---FN-')),\n",
       " (('97', 'Unk'), ('97', None), ('97', 'A-P---FN-')),\n",
       " (('98', 'Unk'), ('98', None), ('98', 'N-P---FN-')),\n",
       " (('99', 'Unk'), ('99', None), ('99', 'A-P---FN-')),\n",
       " (('100', 'Unk'), ('100', None), ('100', 'N-P---FN-')),\n",
       " (('101', 'Unk'), ('101', None), ('101', 'A-P---FN-')),\n",
       " (('102', 'Unk'), ('102', None), ('102', 'N-P---FN-')),\n",
       " (('103', 'Unk'), ('103', None), ('103', 'A-P---FN-')),\n",
       " (('104', 'Unk'), ('104', None), ('104', 'N-P---FN-')),\n",
       " (('[', 'U--------'), ('[', 'U--------'), ('[', 'U--------')),\n",
       " (('1', 'Unk'), ('1', None), ('1', 'N-S---MV-')),\n",
       " ((']', 'U--------'), (']', 'U--------'), (']', 'U--------')),\n",
       " (('Q', 'Unk'), ('Q', None), ('Q', 'N-S---MV-')),\n",
       " (('.', 'U--------'), ('.', 'U--------'), ('.', 'U--------')),\n",
       " (('Mucius', 'Unk'), ('Mucius', None), ('Mucius', 'D--------')),\n",
       " (('augur', 'Unk'), ('augur', None), ('augur', 'D--------')),\n",
       " (('multa', 'A-P---NA-'), ('multa', 'A-P---NA-'), ('multa', 'A-P---NA-')),\n",
       " (('narrare', 'V--PNA---'),\n",
       "  ('narrare', 'V--PNA---'),\n",
       "  ('narrare', 'V--PNA---')),\n",
       " (('de', 'R--------'), ('de', 'R--------'), ('de', 'R--------')),\n",
       " (('C', 'Unk'), ('C', None), ('C', '---------')),\n",
       " (('.', 'U--------'), ('.', 'U--------'), ('.', 'U--------')),\n",
       " (('Laelio', 'Unk'), ('Laelio', None), ('Laelio', 'A-S---NB-')),\n",
       " (('socero', 'Unk'), ('socero', None), ('socero', 'N-S---NB-')),\n",
       " (('suo', 'A-S---NB-'), ('suo', 'A-S---NB-'), ('suo', 'A-S---NB-')),\n",
       " (('memoriter', 'Unk'), ('memoriter', None), ('memoriter', 'D--------')),\n",
       " (('et', 'C--------'), ('et', 'C--------'), ('et', 'C--------')),\n",
       " (('iucunde', 'Unk'), ('iucunde', None), ('iucunde', 'D--------')),\n",
       " (('solebat', 'V3SIIA---'),\n",
       "  ('solebat', 'V3SIIA---'),\n",
       "  ('solebat', 'V3SIIA---')),\n",
       " (('nec', 'C--------'), ('nec', 'C--------'), ('nec', 'C--------')),\n",
       " (('dubitare', 'Unk'), ('dubitare', None), ('dubitare', 'V--PNA---')),\n",
       " (('illum', 'P-S---MA-'), ('illum', 'P-S---MA-'), ('illum', 'P-S---MA-')),\n",
       " (('in', 'R--------'), ('in', 'R--------'), ('in', 'R--------')),\n",
       " (('omni', 'A-S---MB-'), ('omni', 'A-S---FB-'), ('omni', 'A-S---FB-')),\n",
       " (('sermone', 'N-S---MB-'),\n",
       "  ('sermone', 'N-S---MB-'),\n",
       "  ('sermone', 'N-S---FB-')),\n",
       " (('appellare', 'V--PNA---'),\n",
       "  ('appellare', 'V--PNA---'),\n",
       "  ('appellare', 'V--PNA---')),\n",
       " (('sapientem', 'Unk'), ('sapientem', None), ('sapientem', 'N-S---FA-')),\n",
       " ((';', 'Unk'), (';', None), (';', 'U--------')),\n",
       " (('ego', 'P-S---MN-'), ('ego', 'P-S---MN-'), ('ego', 'P-S---MN-')),\n",
       " (('autem', 'C--------'), ('autem', 'C--------'), ('autem', 'C--------')),\n",
       " (('a', 'R--------'), ('a', 'R--------'), ('a', 'R--------')),\n",
       " (('patre', 'N-S---MB-'), ('patre', 'N-S---MB-'), ('patre', 'N-S---MB-')),\n",
       " (('ita', 'D--------'), ('ita', 'D--------'), ('ita', 'D--------')),\n",
       " (('eram', 'V1SIIA---'), ('eram', 'V1SIIA---'), ('eram', 'N-S---FA-')),\n",
       " (('deductus', 'T-SRPPMN-'),\n",
       "  ('deductus', 'T-SRPPMN-'),\n",
       "  ('deductus', 'T-SRPPMN-')),\n",
       " (('ad', 'R--------'), ('ad', 'R--------'), ('ad', 'R--------')),\n",
       " (('Scaevolam', 'Unk'), ('Scaevolam', None), ('Scaevolam', 'N-S---FA-')),\n",
       " (('sumpta', 'Unk'), ('sumpta', None), ('sumpta', 'T-SRPPFN-'))]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(\n",
    "    tagger.tag_tnt(\" \".join([str(w) for w in amicitia_words[100:150]])),\n",
    "    tagger.tag_ngram_123_backoff(\" \".join([str(w) for w in amicitia_words[100:150]])),\n",
    "    tagger.tag_crf(\" \".join([str(w) for w in amicitia_words[100:150]]))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TreeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treetagger import TreeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TREETAGGER_HOME\"] = \"/Users/rromanello/tree-tagger/cmd/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TreeTagger(language=\"latin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['91', 'ADJ:NUM', '@card@'],\n",
       " ['92', 'ADJ:NUM', '@card@'],\n",
       " ['93', 'ADJ:NUM', '@card@'],\n",
       " ['94', 'ADJ:NUM', '@card@'],\n",
       " ['95', 'ADJ:NUM', '@card@'],\n",
       " ['96', 'ADJ:NUM', '@card@'],\n",
       " ['97', 'ADJ:NUM', '@card@'],\n",
       " ['98', 'ADJ:NUM', '@card@'],\n",
       " ['99', 'ADJ:NUM', '@card@'],\n",
       " ['100', 'ADJ:NUM', '@card@'],\n",
       " ['101', 'ADJ:NUM', '@card@'],\n",
       " ['102', 'ADJ:NUM', '@card@'],\n",
       " ['103', 'ADJ:NUM', '@card@'],\n",
       " ['104', 'ADJ:NUM', '@card@'],\n",
       " ['[', 'PUN', '['],\n",
       " ['1', 'ADJ:NUM', '@card@'],\n",
       " [']', 'PUN', ']'],\n",
       " ['Q.', 'ABBR', 'Q.'],\n",
       " ['Mucius', 'ADJ', '<unknown>'],\n",
       " ['augur', 'N:nom', 'augur'],\n",
       " ['multa', 'ADJ', 'multus'],\n",
       " ['narrare', 'V:INF', 'narro'],\n",
       " ['de', 'PREP', 'de'],\n",
       " ['C.', 'ABBR', 'C.'],\n",
       " ['Laelio', 'N:abl', '<unknown>'],\n",
       " ['socero', 'N:abl', 'socer'],\n",
       " ['suo', 'POSS', 'suus'],\n",
       " ['memoriter', 'ADV', 'memoriter'],\n",
       " ['et', 'CC', 'et'],\n",
       " ['iucunde', 'ADJ', '<unknown>'],\n",
       " ['solebat', 'V:IND', 'soleo'],\n",
       " ['nec', 'CC', 'nec'],\n",
       " ['dubitare', 'V:INF', 'dubito'],\n",
       " ['illum', 'DIMOS', 'ille'],\n",
       " ['in', 'PREP', 'in'],\n",
       " ['omni', 'PRON', 'omnis'],\n",
       " ['sermone', 'N:abl', 'sermo'],\n",
       " ['appellare', 'V:INF', 'appello'],\n",
       " ['sapientem', 'N:acc', 'sapiens'],\n",
       " [';', 'SENT', ';'],\n",
       " ['ego', 'PRON', 'ego'],\n",
       " ['autem', 'ADV', 'autem'],\n",
       " ['a', 'PREP', 'a'],\n",
       " ['patre', 'N:abl', 'pater'],\n",
       " ['ita', 'ADV', 'ita'],\n",
       " ['eram', 'ESSE:IND', 'sum'],\n",
       " ['deductus', 'V:PTC:nom', 'deduco'],\n",
       " ['ad', 'PREP', 'ad'],\n",
       " ['Scaevolam', 'NPR', '<unknown>'],\n",
       " ['sumpta', 'V:PTC:nom', 'sumo']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.tag(amicitia_words[100:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6e2cd06a89c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cogito ergo sum\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tt' is not defined"
     ]
    }
   ],
   "source": [
    "tt.tag(\"Cogito ergo sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLTK taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "grk_corpus_importer.import_corpus(\"greek_models_cltk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.tag.pos import POSTag\n",
    "tagger = POSTag('greek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('θεοὺς', 'N-P---MA-'),\n",
       " ('μὲν', 'G--------'),\n",
       " ('αἰτῶ', 'V1SPIA---'),\n",
       " ('τῶνδ', 'P-P---MG-'),\n",
       " ('᾽', None),\n",
       " ('ἀπαλλαγὴν', 'N-S---FA-'),\n",
       " ('πόνων', 'N-P---MG-'),\n",
       " ('φρουρᾶς', 'N-S---FG-'),\n",
       " ('ἐτείας', 'A-S---FG-'),\n",
       " ('μῆκος', 'N-S---NA-')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag_ngram_123_backoff('θεοὺς μὲν αἰτῶ τῶνδ᾽ ἀπαλλαγὴν πόνων φρουρᾶς ἐτείας μῆκος')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('θεοὺς', 'N-P---MA-'),\n",
       " ('μὲν', 'G--------'),\n",
       " ('αἰτῶ', 'V1SPIA---'),\n",
       " ('τῶνδ', 'P-P---NG-'),\n",
       " ('᾽', 'Unk'),\n",
       " ('ἀπαλλαγὴν', 'N-S---FA-'),\n",
       " ('πόνων', 'N-P---MG-'),\n",
       " ('φρουρᾶς', 'N-S---FG-'),\n",
       " ('ἐτείας', 'A-S---FG-'),\n",
       " ('μῆκος', 'N-S---NA-')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag_tnt('θεοὺς μὲν αἰτῶ τῶνδ᾽ ἀπαλλαγὴν πόνων φρουρᾶς ἐτείας μῆκος')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
    "from cltk.tokenize.sentence import TokenizeSentence\n",
    "from cltk.tokenize.word import WordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = WordTokenizer('greek')\n",
    "sentence_tokenizer = TokenizeSentence(\"greek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mat/cltk_data\n",
      "/Users/mat/cltk_data/greek/text/greek_text_perseus/\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschines/aeschin_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschines/aeschin_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.ag_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.ag_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.eum_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.eum_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.lib_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.lib_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.pb_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.pb_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.pers_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.pers_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.seven_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.seven_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.supp_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aeschylus/aesch.supp_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Andocides/andoc_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Andocides/andoc_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Anth/01_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Anth/01_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Anth/02_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Anth/02_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Anth/03_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Anth/03_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Anth/04_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Anth/04_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Anth/05_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Anth/05_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Apollodorus/apollod_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Apollodorus/apollod_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Apollonius/argo_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Apollonius/argo_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Appian/appian.cw_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Appian/appian.cw_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Appian/appian.fw_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Appian/appian.fw_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aretaeus/aret_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aretaeus/aret_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristides/aristid.orat_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristides/aristid.orat_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristides/aristid.rhet_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristides/aristid.rhet_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.ach_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.ach_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.birds_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.birds_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.cl_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.cl_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.eccl_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.eccl_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.frogs_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.frogs_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.kn_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.kn_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.lys_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.lys_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.peace_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.peace_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.pl_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.pl_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.thes_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.thes_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.wasps_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristophanes/aristoph.wasps_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.ath.pol_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.ath.pol_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.econ_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.econ_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.eud.eth_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.eud.eth_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.met_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.met_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.nic.eth_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.nic.eth_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.pol_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.pol_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.rh_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.rh_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.vir_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Aristotle/aristot.vir_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Arrian/arrian.acies_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Arrian/arrian.acies_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Arrian/arrian.anab_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Arrian/arrian.anab_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Arrian/arrian.cuneg_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Arrian/arrian.cuneg_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Arrian/arrian.indica_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Arrian/arrian.indica_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Arrian/arrian.periplous_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Arrian/arrian.periplous_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Arrian/arrian.tactica_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Arrian/arrian.tactica_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath01_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath01_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath02_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath02_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath03_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath03_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath04_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath04_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath05_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath05_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath06_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath06_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath07_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath07_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath08_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath08_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath09_gk.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath09_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath10_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath10_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath11_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath11_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath12_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath12_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath13_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath13_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath14_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath14_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath15_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Athenaeus/ath15_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Bacchylides/bacchyl_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Bacchylides/bacchyl_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Bible/nt_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Bible/nt_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Colluthus/colluthus.01_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Colluthus/colluthus.01_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Demades/demad_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Demades/demad_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Demosthenes/dem01-10_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Demosthenes/dem01-10_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Demosthenes/dem11-20_gk.txt\n",
      "/Users/mat/cltk_data/greek/text/perseus_unicode/Demosthenes/dem11-20_gk.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-99995bcff38a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mbeta_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleach\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0ma_replacer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplacer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0municode_converted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_replacer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;31m#print(unicode_converted)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0municode_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcltk_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/greek/text/perseus_unicode/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/cltk/corpus/greek/beta_to_unicode.py\u001b[0m in \u001b[0;36mbeta_code\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpattern2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0;31m# remove third run, if punct list not used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpattern3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# my modified version of https://github.com/cltk/greek_text_perseus/blob/master/perseus_compiler.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import bleach\n",
    "#from cltk.corpus.classical_greek.replacer import Replacer\n",
    "from cltk.corpus.greek.beta_to_unicode import Replacer\n",
    "\n",
    "\n",
    "home = os.path.expanduser('~')\n",
    "cltk_path = os.path.join(home, 'cltk_data')\n",
    "print(cltk_path)\n",
    "perseus_root = cltk_path + '/greek/text/greek_text_perseus/'\n",
    "print(perseus_root)\n",
    "ignore = [\n",
    "    '.git',\n",
    "    'LICENSE.md',\n",
    "    'README.md',\n",
    "    'cltk_json',\n",
    "    'json',\n",
    "    'perseus_compiler.py'\n",
    "]\n",
    "authors = [d for d in os.listdir(perseus_root) if d not in ignore]\n",
    "\n",
    "for author in authors:\n",
    "    texts = os.listdir(perseus_root + author + '/opensource')\n",
    "    for text in texts:\n",
    "        text_match = re.match(r'.*_gk.xml', text)\n",
    "        if text_match:\n",
    "            gk_file = text_match.group()\n",
    "            txt_file = perseus_root + author + '/opensource/' + gk_file\n",
    "            with open(txt_file) as gk:\n",
    "                html = gk.read()\n",
    "                beta_code = bleach.clean(html, strip=True).upper()\n",
    "                a_replacer = Replacer()\n",
    "                unicode_converted = a_replacer.beta_code(beta_code)\n",
    "                #print(unicode_converted)\n",
    "                unicode_root = cltk_path + '/greek/text/perseus_unicode/'\n",
    "                unic_pres = os.path.isdir(unicode_root)\n",
    "                if unic_pres is True:\n",
    "                    pass\n",
    "                else:\n",
    "                    os.mkdir(unicode_root)\n",
    "                author_path = unicode_root + author\n",
    "                author_path_pres = os.path.isdir(author_path)\n",
    "                if author_path_pres is True:\n",
    "                    pass\n",
    "                else:\n",
    "                    os.mkdir(author_path)\n",
    "                gk_file_txt = os.path.splitext(gk_file)[0] + '.txt'\n",
    "                uni_write = author_path + '/' + gk_file_txt\n",
    "                print(uni_write)\n",
    "                with open(uni_write, 'w') as uni_write:\n",
    "                    uni_write.write(unicode_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    perseusgreek = PlaintextCorpusReader(\n",
    "        cltk_path + '/greek/text/perseus_unicode/', \n",
    "        '.*\\.txt',\n",
    "        word_tokenizer=word_tokenizer, \n",
    "        sent_tokenizer=sentence_tokenizer, \n",
    "        encoding='utf-8'\n",
    "    )    \n",
    "    pass\n",
    "except IOError as e:\n",
    "    pass\n",
    "    # print(\"Corpus not found. Please check that the Latin Library is installed in CLTK_DATA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = perseusgreek.words('Aristophanes/aristoph.birds_gk.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ἐπέγειρον', 'αὐτόν', '.', 'Θεράπων', 'Ἔποποσ', 'οἶδα', 'μὲν', 'σαφῶσ', 'ὅτι', 'ἀχθέσεται', ',', 'σφῷν', 'δ’', 'αὐτὸν', 'οὕνεκ’', 'ἐπεγερῶ', '.', 'Πισθέταιροσ', 'κακῶς', 'σύ', 'γ’', 'ἀπόλοῐ', ',', 'ὥς', 'μ’', 'ἀπέκτεινας', 'δέει', '.', 'Ἐυελπίδησ', 'οἴμοι', 'κακοδαίμων', 'χὠ', 'κολοιός', 'μοἴχεται', 'ὑπὸ', 'τοῦ', 'δέους\\\\', '.', 'Πισθέταιροσ', 'ὦ', 'δειλότατον', 'σὺ', 'θηρίον', ',', 'δείσας', 'ἀφῆκας', 'τὸν', 'κολοιόν', ';', 'Ἐυελπίδησ', 'εἰπέ', 'μοι', ',', 'σὺ', 'δὲ', 'τὴν', 'κορώνην', 'οὐκ', 'ἀφῆκας', 'καταπεσών', ';', 'Πισθέταιροσ', 'μὰ', 'Δί’', 'οὐκ', 'ἔγωγε', '.', 'Ἐυελπίδησ', 'ποῦ', 'γάρ', 'ἐστ’', ';', 'Πισθέταιροσ', 'ἀπέπτετο', '.', 'Ἐυελπίδησ', 'οὐκ', 'ἆρ’', 'ἀφῆκας', ';', 'ὦγάθ’', 'ὡς', 'ἀνδρεῖος', 'εἶ', '.', 'Ἔποψ', 'ἄνοιγε', 'τὴν', 'ὕλην', ',', 'ἵν’', 'ἐξέλθω', 'ποτέ', '.', 'Ἐυελπίδησ', 'ὦ', 'Ἡράκλεις', 'τουτὶ', 'τί', 'ποτ’']\n"
     ]
    }
   ],
   "source": [
    "print(list(birds[1000:1100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ἐπέγειρον', 'Unk'),\n",
       " ('αὐτόν', 'A-S---MA-'),\n",
       " ('.', 'U--------'),\n",
       " ('Θεράπων', 'Unk'),\n",
       " ('Ἔποποσ', 'Unk'),\n",
       " ('οἶδα', 'V1SRIA---'),\n",
       " ('μὲν', 'G--------'),\n",
       " ('σαφῶσ', 'Unk'),\n",
       " ('ὅτι', 'C--------'),\n",
       " ('ἀχθέσεται', 'Unk'),\n",
       " (',', 'U--------'),\n",
       " ('σφῷν', 'P-D---MG-'),\n",
       " ('δ', 'G--------'),\n",
       " ('’', 'Unk'),\n",
       " ('αὐτὸν', 'A-S---MA-'),\n",
       " ('οὕνεκ', 'C--------'),\n",
       " ('’', 'Unk'),\n",
       " ('ἐπεγερῶ', 'Unk'),\n",
       " ('.', 'U--------'),\n",
       " ('Πισθέταιροσ', 'Unk'),\n",
       " ('κακῶς', 'D--------'),\n",
       " ('σύ', 'P-S----N-'),\n",
       " ('γ', 'G--------'),\n",
       " ('’', 'Unk'),\n",
       " ('ἀπόλοῐ', 'Unk'),\n",
       " (',', 'U--------'),\n",
       " ('ὥς', 'C--------'),\n",
       " ('μ', 'P-S---MA-'),\n",
       " ('’', 'Unk'),\n",
       " ('ἀπέκτεινας', 'Unk'),\n",
       " ('δέει', 'N-S---ND-'),\n",
       " ('.', 'U--------'),\n",
       " ('Ἐυελπίδησ', 'Unk'),\n",
       " ('οἴμοι', 'E--------'),\n",
       " ('κακοδαίμων', 'Unk'),\n",
       " ('χὠ', 'L-S---MN-'),\n",
       " ('κολοιός', 'Unk'),\n",
       " ('μοἴχεται', 'Unk'),\n",
       " ('ὑπὸ', 'R--------'),\n",
       " ('τοῦ', 'L-S---NG-'),\n",
       " ('δέους', 'N-S---NG-'),\n",
       " ('\\\\', 'Unk'),\n",
       " ('.', 'U--------'),\n",
       " ('Πισθέταιροσ', 'Unk'),\n",
       " ('ὦ', 'E--------'),\n",
       " ('δειλότατον', 'Unk'),\n",
       " ('σὺ', 'P-S----N-'),\n",
       " ('θηρίον', 'N-S---NN-'),\n",
       " (',', 'U--------'),\n",
       " ('δείσας', 'T-SAPAMN-'),\n",
       " ('ἀφῆκας', 'V2SAIA---'),\n",
       " ('τὸν', 'L-S---MA-'),\n",
       " ('κολοιόν', 'Unk'),\n",
       " (';', 'U--------'),\n",
       " ('Ἐυελπίδησ', 'Unk'),\n",
       " ('εἰπέ', 'V2SAMA---'),\n",
       " ('μοι', 'P-S---MD-'),\n",
       " (',', 'U--------'),\n",
       " ('σὺ', 'P-S---MN-'),\n",
       " ('δὲ', 'G--------'),\n",
       " ('τὴν', 'L-S---FA-'),\n",
       " ('κορώνην', 'N-S---FA-'),\n",
       " ('οὐκ', 'D--------'),\n",
       " ('ἀφῆκας', 'V2SAIA---'),\n",
       " ('καταπεσών', 'Unk'),\n",
       " (';', 'U--------'),\n",
       " ('Πισθέταιροσ', 'Unk'),\n",
       " ('μὰ', 'G--------'),\n",
       " ('Δί', 'Unk'),\n",
       " ('’', 'Unk'),\n",
       " ('οὐκ', 'D--------'),\n",
       " ('ἔγωγε', 'P-S---MN-'),\n",
       " ('.', 'U--------'),\n",
       " ('Ἐυελπίδησ', 'Unk'),\n",
       " ('ποῦ', 'D--------'),\n",
       " ('γάρ', 'G--------'),\n",
       " ('ἐστ', 'V3SPIA---'),\n",
       " ('’', 'Unk'),\n",
       " (';', 'U--------'),\n",
       " ('Πισθέταιροσ', 'Unk'),\n",
       " ('ἀπέπτετο', 'Unk'),\n",
       " ('.', 'U--------'),\n",
       " ('Ἐυελπίδησ', 'Unk'),\n",
       " ('οὐκ', 'D--------'),\n",
       " ('ἆρ', 'D--------'),\n",
       " ('’', 'Unk'),\n",
       " ('ἀφῆκας', 'V2SAIA---'),\n",
       " (';', 'U--------'),\n",
       " ('ὦγάθ', 'Unk'),\n",
       " ('’', 'Unk'),\n",
       " ('ὡς', 'D--------'),\n",
       " ('ἀνδρεῖος', 'Unk'),\n",
       " ('εἶ', 'V2SPIA---'),\n",
       " ('.', 'U--------'),\n",
       " ('Ἔποψ', 'Unk'),\n",
       " ('ἄνοιγε', 'V2SPMA---'),\n",
       " ('τὴν', 'L-S---FA-'),\n",
       " ('ὕλην', 'N-S---FA-'),\n",
       " (',', 'U--------'),\n",
       " ('ἵν', 'C--------'),\n",
       " ('’', 'Unk'),\n",
       " ('ἐξέλθω', 'Unk'),\n",
       " ('ποτέ', 'G--------'),\n",
       " ('.', 'U--------'),\n",
       " ('Ἐυελπίδησ', 'Unk'),\n",
       " ('ὦ', 'E--------'),\n",
       " ('Ἡράκλεις', 'Unk'),\n",
       " ('τουτὶ', 'Unk'),\n",
       " ('τί', 'P-S---NA-'),\n",
       " ('ποτ', 'G--------'),\n",
       " ('’', 'Unk')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag_tnt(\" \".join(birds[1000:1100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TreeTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "### Latin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyCollatinus\n",
    "\n",
    "* Python port of the [Collatinus lemmatizer](https://github.com/biblissima/collatinus)\n",
    "* good if you can read some French (or at least practice it) 😉\n",
    "* the PoS tags used by Collatinus are explained [here](https://github.com/biblissima/collatinus/blob/master/NOTES_Tagger.md)\n",
    "* morphological analysis not readily machine readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import and instantiate the PyCollatinus lemmatizer (`Lemmatiseur`) – and ignore the long list of warnings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: honor has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: aer has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: tethys has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: opes has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: dos has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: corpus has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: ciuis has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: thales has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: poesis has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: manes has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: turris has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: uis has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: nauis has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: apis has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: mare has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: moenia has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: animal has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: mille has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n",
      "/Users/mat/.local/share/virtualenvs/sunoikisis_dc-I3iKJ3Z3/lib/python3.6/site-packages/pycollatinus/parser.py:335: MissingRadical: ille has no radical 1\n",
      "  warnings.warn(gr + \" has no radical {}\".format(numRad), MissingRadical)\n"
     ]
    }
   ],
   "source": [
    "from pycollatinus import Lemmatiseur\n",
    "analyzer = Lemmatiseur()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lemmatiser can take as input a **single word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'desinence': 'ito',\n",
       "  'form': 'cogito',\n",
       "  'lemma': 'cogo',\n",
       "  'morph': '2ème singulier impératif futur actif',\n",
       "  'radical': 'cog'},\n",
       " {'desinence': 'ito',\n",
       "  'form': 'cogito',\n",
       "  'lemma': 'cogo',\n",
       "  'morph': '3ème singulier impératif futur actif',\n",
       "  'radical': 'cog'},\n",
       " {'desinence': 'o',\n",
       "  'form': 'cogito',\n",
       "  'lemma': 'cogito',\n",
       "  'morph': '1ère singulier indicatif présent actif',\n",
       "  'radical': 'cogit'},\n",
       " {'desinence': 'o',\n",
       "  'form': 'cogito',\n",
       "  'lemma': 'cogito',\n",
       "  'morph': '1ère singulier indicatif présent actif',\n",
       "  'radical': 'cogit'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(analyzer.lemmatise(\"Cogito\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or an **entire sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'desinence': 'ito',\n",
       "   'form': 'cogito',\n",
       "   'lemma': 'cogo',\n",
       "   'morph': '2ème singulier impératif futur actif',\n",
       "   'radical': 'cog'},\n",
       "  {'desinence': 'ito',\n",
       "   'form': 'cogito',\n",
       "   'lemma': 'cogo',\n",
       "   'morph': '3ème singulier impératif futur actif',\n",
       "   'radical': 'cog'},\n",
       "  {'desinence': 'o',\n",
       "   'form': 'cogito',\n",
       "   'lemma': 'cogito',\n",
       "   'morph': '1ère singulier indicatif présent actif',\n",
       "   'radical': 'cogit'},\n",
       "  {'desinence': 'o',\n",
       "   'form': 'cogito',\n",
       "   'lemma': 'cogito',\n",
       "   'morph': '1ère singulier indicatif présent actif',\n",
       "   'radical': 'cogit'}],\n",
       " [{'desinence': 'o',\n",
       "   'form': 'ergo',\n",
       "   'lemma': 'ergo',\n",
       "   'morph': '1ère singulier indicatif présent actif',\n",
       "   'radical': 'erg'},\n",
       "  {'desinence': '',\n",
       "   'form': 'ergo',\n",
       "   'lemma': 'ergo',\n",
       "   'morph': '-',\n",
       "   'radical': 'ergo'},\n",
       "  {'desinence': '',\n",
       "   'form': 'ergo',\n",
       "   'lemma': 'ergo',\n",
       "   'morph': 'positif',\n",
       "   'radical': 'ergo'}],\n",
       " [{'desinence': 'um',\n",
       "   'form': 'sum',\n",
       "   'lemma': 'sum',\n",
       "   'morph': '1ère singulier indicatif présent actif',\n",
       "   'radical': 's'}]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(analyzer.lemmatise_multiple(\"Cogito ergo sum\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to output the lemmatisation in a more intellegible way..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\tcogito\t\tcogo 2ème singulier impératif futur actif\n",
      "1.2\tcogito\t\tcogo 3ème singulier impératif futur actif\n",
      "1.3\tcogito\t\tcogito 1ère singulier indicatif présent actif\n",
      "1.4\tcogito\t\tcogito 1ère singulier indicatif présent actif\n",
      "2.1\tergo\t\tergo 1ère singulier indicatif présent actif\n",
      "2.2\tergo\t\tergo -\n",
      "2.3\tergo\t\tergo positif\n",
      "3.1\tsum\t\tsum 1ère singulier indicatif présent actif\n"
     ]
    }
   ],
   "source": [
    "# the analyzer output is essentially a list of lists\n",
    "# for each analyzed token it returns a list of possible lemmata\n",
    "# here we iterate through both lists and display the analysis as we go along\n",
    "\n",
    "for n, result in enumerate(analyzer.lemmatise_multiple(\"Cogito ergo sum\")):\n",
    "    for i, lemma in enumerate(result):\n",
    "        print(\n",
    "            \"{}.{}\\t{}\\t\\t{} {}\".format(\n",
    "                n + 1,\n",
    "                i + 1,\n",
    "                lemma[\"form\"],\n",
    "                lemma[\"lemma\"],\n",
    "                lemma[\"morph\"]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the same but also with PoS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\tcogito\tv\tcogo 2ème singulier impératif futur actif\n",
      "1.2\tcogito\tv\tcogo 3ème singulier impératif futur actif\n",
      "1.3\tcogito\tv\tcogito 1ère singulier indicatif présent actif\n",
      "1.4\tcogito\tv\tcogito 1ère singulier indicatif présent actif\n",
      "2.1\tergo\tv\tergo 1ère singulier indicatif présent actif\n",
      "2.2\tergo\tc\tergo -\n",
      "2.3\tergo\td\tergo positif\n",
      "3.1\tsum\tv\tsum 1ère singulier indicatif présent actif\n"
     ]
    }
   ],
   "source": [
    "# the analyzer output is essentially a list of lists\n",
    "# for each analyzed token it returns a list of possible lemmata\n",
    "# here we iterate through both lists and display the analysis as we go along\n",
    "\n",
    "for n, result in enumerate(analyzer.lemmatise_multiple(\"Cogito ergo sum\", pos=True),):\n",
    "    for i, lemma in enumerate(result):\n",
    "        print(\n",
    "            \"{}.{}\\t{}\\t{}\\t{} {}\".format(\n",
    "                n + 1,\n",
    "                i + 1,\n",
    "                lemma[\"form\"],\n",
    "                lemma[\"pos\"],\n",
    "                lemma[\"lemma\"],\n",
    "                lemma[\"morph\"]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "234px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
